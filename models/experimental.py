# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
    Experimental modules
    è¿™ä¸ªæ¨¡å—å¤§å¤šæ˜¯åœ¨è¿‘å¹´æ¥çš„ä¸€äº›å¥‡æ€å¦™æƒ³çš„è®ºæ–‡ä¸­æå‡ºæ¥çš„ï¼Œyolov5çš„ä½œè€…å°†è¿™äº›æ¨¡å—ä¸yolov5ç›¸ç»“åˆï¼Œè¿›è¡Œå°è¯•ã€‚
"""

"""
    Â·æ³¨é‡Šæ¥æºäºå„ä½å¤§ä½¬çš„è§†é¢‘+åšå®¢ï¼Œæ”¶é›†ä¸æ˜“ï¼Œç¥ä½ æ—©æ—¥å‡ºsciï¼
    Â·ç§‰æŒå¼€æºç²¾ç¥ï¼å–ä¹‹äºå¤§ä½¬ï¼Œç”¨ä¹‹äºå„ä½ï¼
    Â·@Dragon AI 
"""
import math

import numpy as np
import torch
import torch.nn as nn

from models.common import Conv
from utils.downloads import attempt_download


class CrossConv(nn.Module):
    """
        Ghost Convolution å¹»è±¡å·ç§¯  è½»é‡åŒ–ç½‘ç»œå·ç§¯æ¨¡å—
        è®ºæ–‡: https://arxiv.org/abs/1911.11907
        æºç : https://github.com/huawei-noah/ghostnet
        å¸¸è§çš„å‡ ç§ä½¿ç”¨æ–¹å¼: https://github.com/ultralytics/yolov5/issues/2905
    """
    # Cross Convolution Downsample
    def __init__(self, c1, c2, k=3, s=1, g=1, e=1.0, shortcut=False):
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, (1, k), (1, s))
        self.cv2 = Conv(c_, c2, (k, 1), (s, 1), g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))


class Sum(nn.Module):
    """
       åŠ æƒç‰¹å¾èåˆ: å­¦ä¹ ä¸åŒè¾“å…¥ç‰¹å¾çš„é‡è¦æ€§ï¼Œå¯¹ä¸åŒè¾“å…¥ç‰¹å¾æœ‰åŒºåˆ†çš„èåˆ  Weighted sum of 2 or more layers

       æ€æƒ³: ä¼ ç»Ÿçš„ç‰¹å¾èåˆå¾€å¾€åªæ˜¯ç®€å•çš„feature mapå åŠ /ç›¸åŠ  (sum them up), æ¯”å¦‚ä½¿ç”¨concatæˆ–è€…shortcutè¿æ¥, è€Œä¸å¯¹åŒæ—¶åŠ è¿›æ¥çš„
            feature mapè¿›è¡ŒåŒºåˆ†ã€‚ç„¶è€Œ,ä¸åŒçš„è¾“å…¥feature mapå…·æœ‰ä¸åŒçš„åˆ†è¾¨ç‡, å®ƒä»¬å¯¹èåˆè¾“å…¥feature mapçš„è´¡çŒ®ä¹Ÿæ˜¯ä¸åŒçš„, å› æ­¤ç®€å•
            çš„å¯¹ä»–ä»¬è¿›è¡Œç›¸åŠ æˆ–å åŠ å¤„ç†å¹¶ä¸æ˜¯æœ€ä½³çš„æ“ä½œ, æ‰€ä»¥è¿™é‡Œæˆ‘ä»¬æå‡ºäº†ä¸€ç§ç®€å•è€Œé«˜æ•ˆçš„åŠ æƒç‰¹èåˆçš„æœºåˆ¶ã€‚

       ä¸è®ºæ–‡çš„ä¸åŒç‚¹ï¼šè¿™é‡Œçš„æƒé‡å‚æ•°æ˜¯å¯ä»¥å­¦ä¹ çš„ã€‚
       from: https://arxiv.org/abs/1911.09070
   """
    def __init__(self, n, weight=False):  # n: number of inputs
        super().__init__()
        self.weight = weight   # æ˜¯å¦ä½¿ç”¨åŠ æƒæƒé‡èåˆ
        self.iter = range(n - 1)  # åŠ æƒ iter
        if weight:
            self.w = nn.Parameter(-torch.arange(1.0, n) / 2, requires_grad=True) # åˆå§‹åŒ–å¯å­¦ä¹ æƒé‡

    def forward(self, x):
        y = x[0]  # no weight
        if self.weight:
            w = torch.sigmoid(self.w) * 2   # å¾—åˆ°æ¯ä¸€ä¸ªlayerçš„å¯å­¦ä¹ æƒé‡
            for i in self.iter:
                y = y + x[i + 1] * w[i] # åŠ æƒç‰¹å¾èåˆ
        else:
            for i in self.iter:
                y = y + x[i + 1]    # ç‰¹å¾èåˆ
        return y


class MixConv2d(nn.Module):
    """
       Mixed Depthwise Conv æ··åˆæ·±åº¦å·ç§¯ å°±æ˜¯ä½¿ç”¨ä¸åŒå¤§å°çš„å·ç§¯æ ¸å¯¹æ·±åº¦å·ç§¯çš„ä¸åŒchannelåˆ†ç»„å¤„ç†
       å¯ä»¥çœ‹ä½œæ˜¯åˆ†ç»„æ·±åº¦å·ç§¯ + Inceptionç»“æ„çš„å¤šç§å·ç§¯æ ¸æ··ç”¨
       è®ºæ–‡: https://arxiv.org/abs/1907.09595.
       æºç : https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet/mixnet.
   """
    def __init__(self, c1, c2, k=(1, 3), s=1, equal_ch=True):  # ch_in, ch_out, kernel, stride, ch_strategy
        """
                :params c1: è¾“å…¥feature mapçš„é€šé“æ•°
                :params c2: è¾“å‡ºçš„feature mapçš„é€šé“æ•°ï¼ˆè¿™ä¸ªå‡½æ•°çš„å…³é”®ç‚¹å°±æ˜¯å¯¹c2è¿›è¡Œåˆ†ç»„ï¼‰
                :params k: æ··åˆçš„å·ç§¯æ ¸å¤§å° å…¶å®è®ºæ–‡é‡Œæ˜¯[3, 5, 7...]ç”¨çš„æ¯”è¾ƒå¤šçš„
                :params s: æ­¥é•¿ stride
                :params equal_ch: é€šé“åˆ’åˆ†æ–¹å¼ æœ‰å‡ç­‰åˆ’åˆ†å’ŒæŒ‡æ•°åˆ’åˆ†ä¸¤ç§æ–¹å¼  é»˜è®¤æ˜¯å‡ç­‰åˆ’åˆ†
        """
        super().__init__()
        n = len(k)  # number of convolutions

        if equal_ch:
            # å‡ç­‰åˆ’åˆ†é€šé“
            i = torch.linspace(0, n - 1E-6, c2).floor()  # c2 indices
            c_ = [(i == g).sum() for g in range(n)]  # intermediate channels
        else:
            # æŒ‡æ•°åˆ’åˆ†é€šé“
            b = [c2] + [0] * n
            a = np.eye(n + 1, n, k=-1)
            a -= np.roll(a, 1, axis=1)
            a *= np.array(k) ** 2
            a[0] = 1
            c_ = np.linalg.lstsq(a, b, rcond=None)[0].round()  # solve for equal weight indices, ax = b

        self.m = nn.ModuleList(
            [nn.Conv2d(c1, int(c_), k, s, k // 2, groups=math.gcd(c1, int(c_)), bias=False) for k, c_ in zip(k, c_)])
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU()

    def forward(self, x):
        # è¿™é‡Œå’ŒåŸè®ºæ–‡ç•¥æœ‰å‡ºå…¥ï¼Œè¿™é‡ŒåŠ äº†ä¸€ä¸ªshortcutæ“ä½œ
        return self.act(self.bn(torch.cat([m(x) for m in self.m], 1)))

class Ensemble(nn.ModuleList):
    """
        æ¨¡å‹é›†æˆ  Ensemble of models
            é›†æˆå»ºæ¨¡æ˜¯é€šè¿‡ä½¿ç”¨è®¸å¤šä¸åŒçš„å»ºæ¨¡ç®—æ³•æˆ–ä½¿ç”¨ä¸åŒçš„è®­ç»ƒæ•°æ®é›†åˆ›å»ºå¤šä¸ªä¸åŒæ¨¡å‹æ¥é¢„æµ‹ç»“æœçš„è¿‡ç¨‹ã€‚
            åªè¦åŸºç¡€æ¨¡å‹æ˜¯å¤šæ ·ä¸”ç‹¬ç«‹çš„ï¼Œä½¿ç”¨é›†æˆæ–¹æ³•æ—¶æ¨¡å‹çš„é¢„æµ‹è¯¯å·®å°±ä¼šå‡å°ï¼Œå³åœ¨åšå‡ºé¢„æµ‹æ—¶å¯»æ±‚ç¾¤ä½“çš„æ™ºæ…§ã€‚
            å³ä½¿é›†æˆæ¨¡å‹åœ¨æ¨¡å‹ä¸­å…·æœ‰å¤šä¸ªåŸºç¡€æ¨¡å‹ï¼ˆæ±‚å¤šä¸ªæ¨¡å‹çš„å¹³å‡å€¼æˆ–æœ€å¤§å€¼ï¼‰ï¼Œå®ƒä»ä½œä¸ºå•ä¸ªæ¨¡å‹è¿è¡Œå’Œæ‰§è¡Œï¼ˆæœ€ç»ˆè¿˜æ˜¯ä»¥ä¸€ä¸ªç»¼åˆæ¨¡å‹çš„å–æ•´è¿›è¡Œé¢„æµ‹ï¼‰ã€‚
        ç›®çš„: å‡å°‘æ¨¡å‹çš„æ³›åŒ–è¯¯å·®
        https://github.com/ultralytics/yolov5/issues/318
        æ¥æº: https://www.sciencedirect.com/topics/computer-science/ensemble-modeling
    """
    # Ensemble of models
    def __init__(self):
        super().__init__()

    def forward(self, x, augment=False, profile=False, visualize=False):
        y = []
        # é›†æˆæ¨¡å‹ä¸ºå¤šä¸ªæ¨¡å‹æ—¶, åœ¨æ¯ä¸€å±‚forwardè¿ç®—æ—¶, éƒ½è¦è¿è¡Œå¤šä¸ªæ¨¡å‹åœ¨è¯¥å±‚çš„ç»“æœappendè¿›yä¸­
        for module in self:
            y.append(module(x, augment, profile, visualize)[0]) # æ·»åŠ module
        # y = torch.stack(y).max(0)[0]  # max ensemble
        # y = torch.stack(y).mean(0)  # mean ensemble
        y = torch.cat(y, 1)  # # å°†ä¸¤ä¸ªæ¨¡å‹ç»“æœconcat åé¢åšnms(ç­‰äºç¿»äº†ä¸€å€çš„pred) nms ensemble
        return y, None  # inference, train output


def attempt_load(weights, map_location=None, inplace=True, fuse=True):
    """
        è¿™ä¸ªå‡½æ•°ç”¨äºåŠ è½½æ¨¡å‹æƒé‡æ–‡ä»¶å¹¶æ„å»ºæ¨¡å‹ï¼ˆå¯ä»¥æ„é€ æ™®é€šæ¨¡å‹æˆ–è€…é›†æˆæ¨¡å‹ï¼‰ã€‚
                ç”¨åœ¨val.pyã€detect.pyã€train.pyç­‰æ–‡ä»¶ä¸­  ä¸€èˆ¬ç”¨åœ¨æµ‹è¯•ã€éªŒè¯é˜¶æ®µ
        Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a
        :params weights: æ¨¡å‹çš„æƒé‡æ–‡ä»¶åœ°å€ é»˜è®¤weights/yolov5s.pt
                         å¯ä»¥æ˜¯[a]ä¹Ÿå¯ä»¥æ˜¯listæ ¼å¼[a, b]  å¦‚æœæ˜¯listæ ¼å¼å°†è°ƒç”¨ä¸Šé¢çš„æ¨¡å‹é›†æˆå‡½æ•° å¤šæ¨¡å‹è¿ç®— æé«˜æœ€ç»ˆæ¨¡å‹çš„æ³›åŒ–è¯¯å·®
        :params map_location: attempt_downloadå‡½æ•°å‚æ•°  è¡¨ç¤ºæ¨¡å‹è¿è¡Œè®¾å¤‡device
        :params inplace: pytorch 1.7.0 compatibilityè®¾ç½®
    """
    from models.yolo import Detect, Model

    # Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a
    model = Ensemble() # æ¨¡å‹é›†æˆå‡½æ•°

    for w in weights if isinstance(weights, list) else [weights]:
        ckpt = torch.load(attempt_download(w), map_location=map_location)  # load
        if fuse:
            model.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().fuse().eval())  # FP32 model->fuseèåˆ->éªŒè¯æ¨¡å¼
        else:
            model.append(ckpt['ema' if ckpt.get('ema') else 'model'].float().eval())  # without layer fuse

    # Compatibility updates(å…³äºç‰ˆæœ¬å…¼å®¹çš„è®¾ç½®)
    for m in model.modules():
        if type(m) in [nn.Hardswish, nn.LeakyReLU, nn.ReLU, nn.ReLU6, nn.SiLU, Detect, Model]:
            m.inplace = inplace  # pytorch 1.7.0 compatibility
            if type(m) is Detect:
                if not isinstance(m.anchor_grid, list):  # new Detect Layer compatibility
                    delattr(m, 'anchor_grid')
                    setattr(m, 'anchor_grid', [torch.zeros(1)] * m.nl)
        elif type(m) is Conv:
            m._non_persistent_buffers_set = set()  # pytorch 1.6.0 compatibility

    if len(model) == 1: # å•ä¸ªæ¨¡å‹ æ­£å¸¸è¿”å›
        return model[-1]  # return model
    else:   # å¤šä¸ªæ¨¡å‹ ä½¿ç”¨æ¨¡å‹é›†æˆ å¹¶å¯¹æ¨¡å‹å…ˆè¿›è¡Œä¸€äº›å¿…è¦çš„è®¾ç½®
        print(f'Ensemble created with {weights}\n')
        # ç»™æ¯ä¸ªæ¨¡å‹ä¸€ä¸ªnameå±æ€§
        for k in ['names']:
            setattr(model, k, getattr(model[-1], k))
        # ç»™æ¯ä¸ªæ¨¡å‹åˆ†é…strideå±æ€§
        model.stride = model[torch.argmax(torch.tensor([m.stride.max() for m in model])).int()].stride  # max stride
        return model  # return ensemble è¿”å›é›†æˆæ¨¡å‹
