# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
    # Plotting utils è¿™ä¸ªè„šæœ¬éƒ½æ˜¯ä¸€äº›ç”»å›¾å·¥å…·
"""

"""
    Â·æ³¨é‡Šæ¥æºäºå„ä½å¤§ä½¬çš„è§†é¢‘+åšå®¢ï¼Œæ”¶é›†ä¸æ˜“ï¼Œç¥ä½ æ—©æ—¥å‡ºsciï¼
    Â·ç§‰æŒå¼€æºç²¾ç¥ï¼å–ä¹‹äºå¤§ä½¬ï¼Œç”¨ä¹‹äºå„ä½ï¼
    Â·@Dragon AI 
"""

import math
import os
from copy import copy
from pathlib import Path

import cv2
import matplotlib
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import seaborn as sn
import torch
from PIL import Image, ImageDraw, ImageFont

from utils.general import (CONFIG_DIR, FONT, LOGGER, Timeout, check_font, check_requirements, clip_coords,
                           increment_path, is_ascii, is_chinese, try_except, xywh2xyxy, xyxy2xywh)
from utils.metrics import fitness

# è®¾ç½®ä¸€äº›åŸºæœ¬çš„é…ç½®  Settings
RANK = int(os.getenv('RANK', -1))
matplotlib.rc('font', **{'size': 11}) # è‡ªå®šä¹‰matplotlibå›¾ä¸Šå­—ä½“fontå¤§å°size=11

# åœ¨PyCharm é¡µé¢ä¸­æ§åˆ¶ç»˜å›¾æ˜¾ç¤ºä¸å¦
# å¦‚æœè¿™å¥è¯æ”¾åœ¨import matplotlib.pyplot as pltä¹‹å‰å°±ç®—åŠ ä¸Šplt.show()ä¹Ÿä¸ä¼šå†å±å¹•ä¸Šç»˜å›¾ æ”¾åœ¨ä¹‹åå…¶å®æ²¡ä»€ä¹ˆç”¨
matplotlib.use('Agg')  # for writing to files only


class Colors:
    """
        å‡½æ•°åŠŸèƒ½ï¼šè¿™æ˜¯ä¸€ä¸ªé¢œè‰²ç±»ï¼Œç”¨äºé€‰æ‹©ç›¸åº”çš„é¢œè‰²ï¼Œæ¯”å¦‚ç”»æ¡†çº¿çš„é¢œè‰²ï¼Œå­—ä½“é¢œè‰²ç­‰ç­‰ã€‚
    """
    # Ultralytics color palette https://ultralytics.com/
    def __init__(self):
        # hex = matplotlib.colors.TABLEAU_COLORS.values()
        hex = ('FF3838', 'FF9D97', 'FF701F', 'FFB21D', 'CFD231', '48F90A', '92CC17', '3DDB86', '1A9334', '00D4BB',
               '2C99A8', '00C2FF', '344593', '6473FF', '0018EC', '8438FF', '520085', 'CB38FF', 'FF95C8', 'FF37C7')
        # å°†hexåˆ—è¡¨ä¸­æ‰€æœ‰hexæ ¼å¼(åå…­è¿›åˆ¶)çš„é¢œè‰²è½¬æ¢rgbæ ¼å¼çš„é¢œè‰²
        self.palette = [self.hex2rgb('#' + c) for c in hex]
        # é¢œè‰²ä¸ªæ•°
        self.n = len(self.palette)

    def __call__(self, i, bgr=False):
        # æ ¹æ®è¾“å…¥çš„index é€‰æ‹©å¯¹åº”çš„rgbé¢œè‰²
        c = self.palette[int(i) % self.n]
        # è¿”å›é€‰æ‹©çš„é¢œè‰² é»˜è®¤æ˜¯rgb
        return (c[2], c[1], c[0]) if bgr else c

    @staticmethod
    def hex2rgb(h):  # rgb order (PIL)
        return tuple(int(h[1 + i:1 + i + 2], 16) for i in (0, 2, 4))


colors = Colors()  # åˆå§‹åŒ–Colorså¯¹è±¡ ä¸‹é¢è°ƒç”¨colorsçš„æ—¶å€™ä¼šè°ƒç”¨__call__å‡½æ•°


def check_pil_font(font=FONT, size=10):
    # Return a PIL TrueType Font, downloading to CONFIG_DIR if necessary
    font = Path(font)
    font = font if font.exists() else (CONFIG_DIR / font.name)
    try:
        return ImageFont.truetype(str(font) if font.exists() else font.name, size)
    except Exception:  # download if missing
        check_font(font)
        try:
            return ImageFont.truetype(str(font), size)
        except TypeError:
            check_requirements('Pillow>=8.4.0')  # known issue https://github.com/ultralytics/yolov5/issues/5374


class Annotator:
    if RANK in (-1, 0):
        check_pil_font()  # download TTF if necessary

    # YOLOv5 Annotator for train/val mosaics and jpgs and detect/hub inference annotations
    def __init__(self, im, line_width=None, font_size=None, font='Arial.ttf', pil=False, example='abc'):
        assert im.data.contiguous, 'Image not contiguous. Apply np.ascontiguousarray(im) to Annotator() input images.'
        self.pil = pil or not is_ascii(example) or is_chinese(example)
        if self.pil:  # use PIL
            self.im = im if isinstance(im, Image.Image) else Image.fromarray(im)
            self.draw = ImageDraw.Draw(self.im)
            self.font = check_pil_font(font='Arial.Unicode.ttf' if is_chinese(example) else font,
                                       size=font_size or max(round(sum(self.im.size) / 2 * 0.035), 12))
        else:  # use cv2
            self.im = im
        self.lw = line_width or max(round(sum(im.shape) / 2 * 0.003), 2)  # line width

    def box_label(self, box, label='', color=(128, 128, 128), txt_color=(255, 255, 255)):
        # Add one xyxy box to image with label
        if self.pil or not is_ascii(label):
            self.draw.rectangle(box, width=self.lw, outline=color)  # box
            if label:
                bbox = self.font.getbbox(label)  # è·å–æ–‡æœ¬çš„è¾¹ç•Œæ¡†
                w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]  # è®¡ç®—æ–‡æœ¬çš„å®½åº¦å’Œé«˜åº¦
                outside = box[1] - h >= 0  # label fits outside box
                self.draw.rectangle((box[0],
                                     box[1] - h if outside else box[1],
                                     box[0] + w + 1,
                                     box[1] + 1 if outside else box[1] + h + 1), fill=color)
                self.draw.text((box[0], box[1] - h if outside else box[1]), label, fill=txt_color, font=self.font)
        else:  # cv2
            p1, p2 = (int(box[0]), int(box[1])), (int(box[2]), int(box[3]))
            cv2.rectangle(self.im, p1, p2, color, thickness=self.lw, lineType=cv2.LINE_AA)
            if label:
                tf = max(self.lw - 1, 1)  # font thickness
                w, h = cv2.getTextSize(label, 0, fontScale=self.lw / 3, thickness=tf)[0]  # text width, height
                outside = p1[1] - h - 3 >= 0  # label fits outside box
                p2 = p1[0] + w, p1[1] - h - 3 if outside else p1[1] + h + 3
                cv2.rectangle(self.im, p1, p2, color, -1, cv2.LINE_AA)  # filled
                cv2.putText(self.im, label, (p1[0], p1[1] - 2 if outside else p1[1] + h + 2), 0, self.lw / 3, txt_color,
                            thickness=tf, lineType=cv2.LINE_AA)

    def rectangle(self, xy, fill=None, outline=None, width=1):
        # Add rectangle to image (PIL-only)
        self.draw.rectangle(xy, fill, outline, width)

    def text(self, xy, text, txt_color=(255, 255, 255)):
        # Add text to image (PIL-only)
        bbox = self.font.getbbox(text)  # è·å–æ–‡æœ¬çš„è¾¹ç•Œæ¡†
        w, h = bbox[2] - bbox[0], bbox[3] - bbox[1]  # è®¡ç®—æ–‡æœ¬çš„å®½åº¦å’Œé«˜åº¦
        self.draw.text((xy[0], xy[1] - h + 1), text, fill=txt_color, font=self.font)

    def result(self):
        # Return annotated image as array
        return np.asarray(self.im)


def feature_visualization(x, module_type, stage, n=32, save_dir=Path('runs/detect/100è½®+YOLOV6.1åŸå‹ç»“æœ')):
    """
        åŠŸèƒ½å‡½æ•°ï¼šç”¨æ¥å¯è§†åŒ–feature mapçš„ï¼Œå¯è§†åŒ–feature map(æ¨¡å‹ä»»æ„å±‚éƒ½å¯ä»¥ç”¨)ï¼Œè€Œä¸”å¯ä»¥å®ç°å¯è§†åŒ–ç½‘ç»œä¸­ä»»æ„ä¸€å±‚çš„feature mapã€‚
        è¢«è°ƒç”¨ï¼šåœ¨yolo.pyçš„Modelç±»ä¸­çš„forward_onceå‡½æ•°ä¸­
    """

    """
        :params x: Features map   [bs, channels, height, width]
        :params module_type: Module type
        :params stage: Module stage within model
        :params n: Maximum number of feature maps to plot
    """
    if 'Detect' not in module_type:
        batch, channels, height, width = x.shape  # batch, channels, height, width
        if height > 1 and width > 1:
            f = save_dir / f"stage{stage}_{module_type.split('.')[-1]}_features.png"  # filename

            # torch.chunk: ä¸torch.cat()åŸç†ç›¸å å°†tensor xæŒ‰dimï¼ˆè¡Œæˆ–åˆ—ï¼‰åˆ†å‰²æˆchannelsä¸ªtensorå—, è¿”å›çš„æ˜¯ä¸€ä¸ªå…ƒç»„
            # å°†ç¬¬2ä¸ªç»´åº¦(channels)å°†xåˆ†æˆchannelsä»½  æ¯å¼ å›¾æœ‰ä¸‰ä¸ªblock batchå¼ å›¾  blocks=len(blocks)=3*batch
            blocks = torch.chunk(x[0].cpu(), channels, dim=0)  # select batch index 0, block by channels
            n = min(n, channels)  # æ€»å…±å¯è§†åŒ–çš„feature mapæ•°é‡
            fig, ax = plt.subplots(math.ceil(n / 8), 8, tight_layout=True)  # 8 rows x n/8 cols
            ax = ax.ravel()
            plt.subplots_adjust(wspace=0.05, hspace=0.05)
            for i in range(n):
                ax[i].imshow(blocks[i].squeeze())  # cmap='gray'
                ax[i].axis('off')

            LOGGER.info(f'Saving {f}... ({n}/{channels})')
            plt.savefig(f, dpi=300, bbox_inches='tight')
            plt.close()
            np.save(str(f.with_suffix('.npy')), x[0].cpu().numpy())  # npy save


def hist2d(x, y, n=100):
    """
        å‡½æ•°åŠŸèƒ½ï¼šä½¿ç”¨numpyå·¥å…·ç”»å‡º2dç›´æ–¹å›¾ã€‚å¤§å¤šæ•°éƒ½æ˜¯è°ƒç”¨å·¥å…·åŒ…å°è£…å¥½çš„2dç›´æ–¹å›¾æ–¹æ³•ã€‚
        è¢«è°ƒç”¨ï¼šåœ¨plot_evolutionå‡½æ•°å’Œplot_test_txtå‡½æ•°ä¸­ä½¿ç”¨ã€‚
    """
    """ç”¨åœ¨plot_evolution
        ä½¿ç”¨numpyç”»å‡º2dç›´æ–¹å›¾
        2d histogram used in labels.png and evolve.png
        """
    # xedges: è¿”å›åœ¨start=x.min()å’Œstop=x.max()ä¹‹é—´è¿”å›å‡åŒ€é—´éš”çš„nä¸ªæ•°æ®
    xedges, yedges = np.linspace(x.min(), x.max(), n), np.linspace(y.min(), y.max(), n)
    # np.histogram2d: 2dç›´æ–¹å›¾  x: xè½´åæ ‡  y: yè½´åæ ‡  (xedges, yedges): bins  x, yè½´çš„é•¿æ¡å½¢æ•°ç›®
    # è¿”å›hist: ç›´æ–¹å›¾å¯¹è±¡   xedges: xè½´å¯¹è±¡  yedges: yè½´å¯¹è±¡
    hist, xedges, yedges = np.histogram2d(x, y, (xedges, yedges))
    # np.clip: æˆªå–å‡½æ•° ä»¤ç›®æ ‡å†…æ‰€æœ‰æ•°æ®éƒ½å±äºä¸€ä¸ªèŒƒå›´ [0, hist.shape[0] - 1] å°äº0çš„ç­‰äº0 å¤§äºåŒç†
    # np.digitize ç”¨äºåˆ†åŒº
    xidx = np.clip(np.digitize(x, xedges) - 1, 0, hist.shape[0] - 1)    # xè½´åæ ‡
    yidx = np.clip(np.digitize(y, yedges) - 1, 0, hist.shape[1] - 1)    # yè½´åæ ‡
    return np.log(hist[xidx, yidx])




# ================================================å¯¹æ£€æµ‹åˆ°çš„ç›®æ ‡æ ¼å¼è¿›è¡Œå¤„ç†ï¼ˆoutput_to_targetï¼‰ç„¶åå†å°†å…¶ç”»æ¡†æ˜¾ç¤ºåœ¨åŸå›¾ä¸Šï¼ˆplot_imagesï¼‰==============================

def output_to_target(output):
    """
        å‡½æ•°åŠŸèƒ½ï¼šè¿™ä¸ªå‡½æ•°æ˜¯ç”¨äºå°†ç»è¿‡nmsåçš„output [num_objï¼Œx1y1x2y2+conf+cls] -> [num_objï¼Œbatch_id+class+xywh+conf]è½¬å˜predictçš„æ ¼å¼
                    åœ¨ç”»å›¾æ“ä½œplot_imagesä¹‹å‰ä»¥ä¾¿åœ¨plot_imagesä¸­è¿›è¡Œç»˜å›¾ + æ˜¾ç¤ºlabelã€‚
        è¢«è°ƒç”¨ï¼šç”¨åœ¨test.pyä¸­è¿›è¡Œç»˜åˆ¶å‰3ä¸ªbatchçš„é¢„æµ‹æ¡†predictions å› ä¸ºåªæœ‰predictionséœ€è¦ä¿®æ”¹æ ¼å¼ targetæ˜¯ä¸éœ€è¦ä¿®æ”¹æ ¼å¼çš„
    """
    """
        :params output: list{tensor(8)}åˆ†åˆ«å¯¹åº”ç€å½“å‰batchçš„8(batch_size)å¼ å›¾ç‰‡åšå®Œnmsåçš„ç»“æœ
                        listä¸­æ¯ä¸ªtensor[n, 6]  nè¡¨ç¤ºå½“å‰å›¾ç‰‡æ£€æµ‹åˆ°çš„ç›®æ ‡ä¸ªæ•°  6=x1y1x2y2+conf+cls

        :return np.array(targets): [num_targets, batch_id+class+xywh+conf]  å…¶ä¸­num_targetsä¸ºå½“å‰batchä¸­æ‰€æœ‰æ£€æµ‹åˆ°ç›®æ ‡æ¡†çš„ä¸ªæ•°
    """
    # Convert model output to target format [batch_id, class_id, x, y, w, h, conf]
    targets = []
    for i, o in enumerate(output):   # å¯¹æ¯å¼ å›¾ç‰‡åˆ†åˆ«åšå¤„ç†
        for *box, conf, cls in o.cpu().numpy(): # å¯¹æ¯å¼ å›¾ç‰‡çš„æ¯ä¸ªæ£€æµ‹åˆ°çš„ç›®æ ‡æ¡†è¿›è¡Œconvertæ ¼å¼
            targets.append([i, cls, *list(*xyxy2xywh(np.array(box)[None])), conf])
    return np.array(targets)


def plot_images(images, targets, paths=None, fname='images.jpg', names=None, max_size=1920, max_subplots=16):
    """
        å‡½æ•°åŠŸèƒ½ï¼šåœ¨output_to_targetå‡½æ•°ä¹‹åï¼Œç»˜åˆ¶ä¸€ä¸ªbatchçš„æ‰€æœ‰å›¾ç‰‡çš„æ¡†æ¡†ï¼ˆçœŸå®æ¡†æˆ–é¢„æµ‹æ¡†ï¼‰ï¼Œ
                                    æ˜¯å°†ä¸€ä¸ªbatchçš„å›¾ç‰‡éƒ½æ”¾åœ¨ä¸€ä¸ªå¤§å›¾mosaicä¸Šé¢ï¼Œæ”¾ä¸ä¸‹åˆ é™¤ã€‚
        è¢«è°ƒç”¨ï¼š ç”¨åœ¨test.pyã€train.pyä¸­ï¼Œé’ˆå¯¹çš„ä¹Ÿä¸å†æ˜¯ä¸€å¼ å›¾ç‰‡ä¸€ä¸ªæ¡†ï¼Œè€Œæ˜¯æ•´ä¸ªbatchä¸­çš„æ‰€æœ‰æ¡†ã€‚
        
    """
    """
        :params images: å½“å‰batchçš„æ‰€æœ‰å›¾ç‰‡  Tensor [batch_size, 3, h, w]  ä¸”å›¾ç‰‡éƒ½æ˜¯å½’ä¸€åŒ–åçš„
        :params targets:  ç›´æ¥æ¥è‡ªtarget: Tensor[num_target, img_index+class+xywh]  [num_target, 6]
                          æ¥è‡ªoutput_to_target: Tensor[num_pred, batch_id+class+xywh+conf] [num_pred, 7]
        :params paths: tuple  å½“å‰batchä¸­æ‰€æœ‰å›¾ç‰‡çš„åœ°å€
                       å¦‚: '..\\datasets\\coco128\\images\\train2017\\000000000315.jpg'
        :params fname: æœ€ç»ˆä¿å­˜çš„æ–‡ä»¶è·¯å¾„ + åå­—  runs\train\exp8\train_batch2.jpg
        :params names: ä¼ å…¥çš„ç±»å ä»class indexå¯ä»¥ç›¸åº”çš„keyå€¼  ä½†æ˜¯é»˜è®¤æ˜¯None åªæ˜¾ç¤ºclass indexä¸æ˜¾ç¤ºç±»å
        :params max_size: å›¾ç‰‡çš„æœ€å¤§å°ºå¯¸640  å¦‚æœimagesæœ‰å›¾ç‰‡çš„å¤§å°(w/h)å¤§äº640åˆ™éœ€è¦resize å¦‚æœéƒ½æ˜¯å°äº640åˆ™ä¸éœ€è¦resize
        :params max_subplots: æœ€å¤§å­å›¾ä¸ªæ•° 16
        :params mosaic: ä¸€å¼ å¤§å›¾  æœ€å¤šå¯ä»¥æ˜¾ç¤ºmax_subplotså¼ å›¾ç‰‡  å°†æ€»å¤šçš„å›¾ç‰‡(åŒ…æ‹¬å„è‡ªçš„labelæ¡†æ¡†)ä¸€èµ·è´´åœ¨ä¸€èµ·æ˜¾ç¤º
                        mosaicæ¯å¼ å›¾ç‰‡çš„å·¦ä¸Šæ–¹è¿˜ä¼šæ˜¾ç¤ºå½“å‰å›¾ç‰‡çš„åå­—  æœ€å¥½ä»¥fnameä¸ºåä¿å­˜èµ·æ¥
    """
    # Plot image grid with labels
    if isinstance(images, torch.Tensor):
        images = images.cpu().float().numpy()   # tensor -> numpy array
    if isinstance(targets, torch.Tensor):
        targets = targets.cpu().numpy()

    # åå½’ä¸€åŒ– å°†å½’ä¸€åŒ–åçš„å›¾ç‰‡è¿˜åŸ  un-normalise
    if np.max(images[0]) <= 1:
        images *= 255  # de-normalise (optional)
    bs, _, h, w = images.shape  # batch size, _, height, width
    bs = min(bs, max_subplots)  # # å­å›¾æ€»æ•°  æ­£æ–¹å½¢  limit plot images  4 limit plot images
    ns = np.ceil(bs ** 0.5)  # ns=æ¯è¡Œ/æ¯åˆ—æœ€å¤§å­å›¾ä¸ªæ•°  å­å›¾æ€»æ•°=ns*ns ceilå‘ä¸Šå–æ•´  2

    # Build Image
    # np.full è¿”å›ä¸€ä¸ªæŒ‡å®šå½¢çŠ¶ã€ç±»å‹å’Œæ•°å€¼çš„æ•°ç»„
    # shape: (int(ns * h), int(ns * w), 3) (1024, 1024, 3)  å¡«å……çš„å€¼: 255   dtype å¡«å……ç±»å‹: np.uint8
    mosaic = np.full((int(ns * h), int(ns * w), 3), 255, dtype=np.uint8)  # init
    # å¯¹batchå†…æ¯å¼ å›¾ç‰‡
    for i, im in enumerate(images):
        # å¦‚æœå›¾ç‰‡è¦è¶…è¿‡max_subplotsæˆ‘ä»¬å°±ä¸ç®¡äº†
        if i == max_subplots:  # if last batch has fewer images than we expect
            break

        # (block_x, block_y) ç›¸å½“äºæ˜¯å·¦ä¸Šè§’çš„å·¦è¾¹
        x, y = int(w * (i // ns)), int(h * (i % ns))  # block origin
        im = im.transpose(1, 2, 0)
        mosaic[y:y + h, x:x + w, :] = im

    # Resize (optional)
    # Check if we should resize
    # å¦‚æœimagesæœ‰å›¾ç‰‡çš„å¤§å°(w/h)å¤§äº640åˆ™éœ€è¦resize å¦‚æœéƒ½æ˜¯å°äº640åˆ™ä¸éœ€è¦resize
    scale = max_size / ns / max(h, w)

    if scale < 1:# å¦‚æœscale_factor < 1è¯´æ˜h/wè¶…è¿‡max_size éœ€è¦resizeå›æ¥
        h = math.ceil(scale * h)
        w = math.ceil(scale * w)
        mosaic = cv2.resize(mosaic, tuple(int(x * ns) for x in (w, h)))

    # Annotate
    fs = int((h + w) * ns * 0.01)  # font size
    annotator = Annotator(mosaic, line_width=round(fs / 10), font_size=fs, pil=True, example=names)
    for i in range(i + 1):
        x, y = int(w * (i // ns)), int(h * (i % ns))  # block origin
        annotator.rectangle([x, y, x + w, y + h], None, (255, 255, 255), width=2)  # borders
        if paths:
            annotator.text((x + 5, y + 5 + h), text=Path(paths[i]).name[:40], txt_color=(220, 220, 220))  # filenames
        if len(targets) > 0:
             # æ±‚å‡ºå±äºè¿™å¼ imgçš„target
            ti = targets[targets[:, 0] == i]  # image targets
            # å°†è¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰targetçš„xywh -> xyxy
            boxes = xywh2xyxy(ti[:, 2:6]).T
            # å¾—åˆ°è¿™å¼ å›¾ç‰‡æ‰€æœ‰targetçš„ç±»åˆ«classes
            classes = ti[:, 1].astype('int')
            # å¦‚æœimage_targets.shape[1] == 6åˆ™è¯´æ˜æ²¡æœ‰ç½®ä¿¡åº¦ä¿¡æ¯(æ­¤æ—¶targetå®é™…ä¸Šæ˜¯çœŸå®æ¡†)
            # å¦‚æœé•¿åº¦ä¸º7åˆ™ç¬¬7ä¸ªä¿¡æ¯å°±æ˜¯ç½®ä¿¡åº¦ä¿¡æ¯(æ­¤æ—¶targetä¸ºé¢„æµ‹æ¡†ä¿¡æ¯)
            labels = ti.shape[1] == 6  # labels if no conf column
            # å¾—åˆ°å½“å‰è¿™å¼ å›¾çš„æ‰€æœ‰targetçš„ç½®ä¿¡åº¦ä¿¡æ¯(pred) å¦‚æœæ²¡æœ‰å°±ä¸ºç©º(çœŸå®label)
            # check for confidence presence (label vs pred)
            conf = None if labels else ti[:, 6]  # check for confidence presence (label vs pred)

            if boxes.shape[1]:   # boxes.shape[1]ä¸ä¸ºç©ºè¯´æ˜è¿™å¼ å›¾æœ‰targetç›®æ ‡
                if boxes.max() <= 1.01:  # if normalized with tolerance 0.01
                    # å› ä¸ºå›¾ç‰‡æ˜¯åå½’ä¸€åŒ–çš„ æ‰€ä»¥è¿™é‡Œboxesä¹Ÿåå½’ä¸€åŒ–
                    boxes[[0, 2]] *= w  # scale to pixels
                    boxes[[1, 3]] *= h
                elif scale < 1:  
                    # å¦‚æœscale_factor < 1 è¯´æ˜resizeè¿‡, é‚£ä¹ˆboxesä¹Ÿè¦ç›¸åº”å˜åŒ–
                    # absolute coords need scale if image scales
                    boxes *= scale
            # ä¸Šé¢å¾—åˆ°çš„boxesä¿¡æ¯æ˜¯ç›¸å¯¹imgè¿™å¼ å›¾ç‰‡çš„æ ‡ç­¾ä¿¡æ¯ å› ä¸ºæˆ‘ä»¬æœ€ç»ˆæ˜¯è¦å°†imgè´´åˆ°mosaicä¸Š æ‰€ä»¥è¿˜è¦å˜æ¢label->mosaic
            boxes[[0, 2]] += x
            boxes[[1, 3]] += y
            
             # å°†å½“å‰çš„å›¾ç‰‡imgçš„æ‰€æœ‰æ ‡ç­¾boxesç”»åˆ°mosaicä¸Š
            for j, box in enumerate(boxes.T.tolist()):
                # éå†æ¯ä¸ªbox
                cls = classes[j]    # å¾—åˆ°è¿™ä¸ªboxçš„class index
                color = colors(cls) # å¾—åˆ°è¿™ä¸ªboxæ¡†çº¿çš„é¢œè‰²
                cls = names[cls] if names else cls  # å¦‚æœä¼ å…¥ç±»åå°±æ˜¾ç¤ºç±»å å¦‚æœæ²¡ä¼ å…¥ç±»åå°±æ˜¾ç¤ºclass index

                # å¦‚æœlabelsä¸ä¸ºç©ºè¯´æ˜æ˜¯åœ¨æ˜¾ç¤ºçœŸå®target ä¸éœ€è¦confç½®ä¿¡åº¦ ç›´æ¥æ˜¾ç¤ºlabelå³å¯
                # å¦‚æœconf[j] > 0.25 é¦–å…ˆè¯´æ˜æ˜¯åœ¨æ˜¾ç¤ºpred ä¸”è¿™ä¸ªboxçš„confå¿…é¡»å¤§äº0.25 ç›¸å½“äºåˆæ˜¯ä¸€è½®nmsç­›é€‰ æ˜¾ç¤ºlabel + conf
                if labels or conf[j] > 0.25:  # 0.25 conf thresh
                    label = f'{cls}' if labels else f'{cls} {conf[j]:.1f}'
                    annotator.box_label(box, label, color=color)
    annotator.im.save(fname)  # save

# ================================================================================================================================================

def plot_lr_scheduler(optimizer, scheduler, epochs=300, save_dir=''):
    """
        å‡½æ•°åŠŸèƒ½ï¼šç”¨æ¥ç”»å‡ºåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ¯ä¸ªepochçš„å­¦ä¹ ç‡å˜åŒ–æƒ…å†µ
        è¢«è°ƒç”¨ï¼šç”¨åœ¨train.pyä¸­å­¦ä¹ ç‡è®¾ç½®åå®ç°å¯è§†åŒ–
    """
    """
        :params optimizer: ä¼˜åŒ–å™¨
        :params scheduler: ç­–ç•¥è°ƒæ•´å™¨
        :params epochs: x
        :params save_dir: lrå›¾ç‰‡ ä¿å­˜åœ°å€
    """
    # Plot LR simulating training for full epochs
    optimizer, scheduler = copy(optimizer), copy(scheduler)  # do not modify originals
    y = [] # å­˜æ”¾æ¯ä¸ªepochçš„å­¦ä¹ ç‡

    # ä»optimizerä¸­å–å­¦ä¹ ç‡ ä¸€ä¸ªepochå–ä¸€ä¸ª å…±å–epochsä¸ª æ¯å–ä¸€æ¬¡éœ€è¦ä½¿ç”¨scheduler.stepæ›´æ–°ä¸‹ä¸€ä¸ªepochçš„å­¦ä¹ ç‡
    for _ in range(epochs):
        scheduler.step()    # æ›´æ–°ä¸‹ä¸€ä¸ªepochçš„å­¦ä¹ ç‡
        # ptimizer.param_groups[0]['lr']: å–ä¸‹ä¸€ä¸ªepochçš„å­¦ä¹ ç‡lr
        y.append(optimizer.param_groups[0]['lr'])

    plt.plot(y, '.-', label='LR') # æ²¡æœ‰ä¼ å…¥x é»˜è®¤ä¼šä¼ å…¥ 0..epochs-1
    plt.xlabel('epoch')
    plt.ylabel('LR')
    plt.grid()
    plt.xlim(0, epochs)
    plt.ylim(0)
    plt.savefig(Path(save_dir) / 'LR.png', dpi=200) # ä¿å­˜
    plt.close()


def plot_val_txt():  # from utils.plots import *; plot_val()
    """
        å‡½æ•°åŠŸèƒ½ï¼šåˆ©ç”¨test.pyä¸­ç”Ÿæˆçš„test.txtæ–‡ä»¶ï¼ˆæˆ–è€…å…¶ä»–çš„*.txtæ–‡ä»¶ï¼‰ï¼Œç”»å‡ºå…¶xyç›´æ–¹å›¾å’ŒxyåŒç›´æ–¹å›¾ã€‚
    """
    # Plot val.txt histograms
    x = np.loadtxt('val.txt', dtype=np.float32)
    box = xyxy2xywh(x[:, :4])
    cx, cy = box[:, 0], box[:, 1]

    fig, ax = plt.subplots(1, 1, figsize=(6, 6), tight_layout=True)
    ax.hist2d(cx, cy, bins=600, cmax=10, cmin=0)
    ax.set_aspect('equal')
    plt.savefig('hist2d.png', dpi=300)

    fig, ax = plt.subplots(1, 2, figsize=(12, 6), tight_layout=True)
    ax[0].hist(cx, bins=600)
    ax[1].hist(cy, bins=600)
    plt.savefig('hist1d.png', dpi=200)


def plot_targets_txt():  # from utils.plots import *; plot_targets_txt()
    """
        å‡½æ•°åŠŸèƒ½ï¼šåˆ©ç”¨targets.txtï¼ˆçœŸå®æ¡†çš„xywhï¼‰ç”»å‡ºå…¶ç›´æ–¹å›¾ã€‚
    """
    # Plot targets.txt histograms
    x = np.loadtxt('targets.txt', dtype=np.float32).T
    s = ['x targets', 'y targets', 'width targets', 'height targets']
    fig, ax = plt.subplots(2, 2, figsize=(8, 8), tight_layout=True)
    ax = ax.ravel() # å°†å¤šç»´æ•°ç»„é™ä½ä¸€ç»´
    for i in range(4):
        ax[i].hist(x[i], bins=100, label=f'{x[i].mean():.3g} +/- {x[i].std():.3g}')
        ax[i].legend()  # æ˜¾ç¤ºä¸Šè¡Œlabelå›¾ä¾‹
        ax[i].set_title(s[i])
    plt.savefig('targets.jpg', dpi=200)


def plot_val_study(file='', dir='', x=None):  # from utils.plots import *; plot_val_study()
    # Plot file=study.txt generated by val.py (or plot all study*.txt in dir)
    save_dir = Path(file).parent if file else Path(dir)
    plot2 = False  # plot additional results
    if plot2:
        ax = plt.subplots(2, 4, figsize=(10, 6), tight_layout=True)[1].ravel()

    fig2, ax2 = plt.subplots(1, 1, figsize=(8, 4), tight_layout=True)
    # for f in [save_dir / f'study_coco_{x}.txt' for x in ['yolov5n6', 'yolov5s6', 'yolov5m6', 'yolov5l6', 'yolov5x6']]:
    for f in sorted(save_dir.glob('study*.txt')):
        y = np.loadtxt(f, dtype=np.float32, usecols=[0, 1, 2, 3, 7, 8, 9], ndmin=2).T
        x = np.arange(y.shape[1]) if x is None else np.array(x)
        if plot2:
            s = ['P', 'R', 'mAP@.5', 'mAP@.5:.95', 't_preprocess (ms/img)', 't_inference (ms/img)', 't_NMS (ms/img)']
            for i in range(7):
                ax[i].plot(x, y[i], '.-', linewidth=2, markersize=8)
                ax[i].set_title(s[i])

        j = y[3].argmax() + 1
        ax2.plot(y[5, 1:j], y[3, 1:j] * 1E2, '.-', linewidth=2, markersize=8,
                 label=f.stem.replace('study_coco_', '').replace('yolo', 'YOLO'))

    ax2.plot(1E3 / np.array([209, 140, 97, 58, 35, 18]), [34.6, 40.5, 43.0, 47.5, 49.7, 51.5],
             'k.-', linewidth=2, markersize=8, alpha=.25, label='EfficientDet')

    ax2.grid(alpha=0.2)
    ax2.set_yticks(np.arange(20, 60, 5))
    ax2.set_xlim(0, 57)
    ax2.set_ylim(25, 55)
    ax2.set_xlabel('GPU Speed (ms/img)')
    ax2.set_ylabel('COCO AP val')
    ax2.legend(loc='lower right')
    f = save_dir / 'study.png'
    print(f'Saving {f}...')
    plt.savefig(f, dpi=300)


@try_except  # known issue https://github.com/ultralytics/yolov5/issues/5395
@Timeout(30)  # known issue https://github.com/ultralytics/yolov5/issues/5611
def plot_labels(labels, names=(), save_dir=Path('')):
    """
        å‡½æ•°åŠŸèƒ½ï¼šæ ¹æ®ä»datasetsä¸­å–åˆ°çš„labelsï¼Œåˆ†æå…¶ç±»åˆ«åˆ†å¸ƒï¼Œç”»å‡ºlabelsç›¸å…³ç›´æ–¹å›¾ä¿¡æ¯ã€‚æœ€ç»ˆä¼šç”Ÿæˆlabels_correlogram.jpgå’Œlabels.jpgä¸¤å¼ å›¾ç‰‡ã€‚
                    labels_correlogram.jpgï¼šåŒ…å«æ‰€æœ‰æ ‡ç­¾çš„ xï¼Œyï¼Œwï¼Œhçš„å¤šå˜é‡è”åˆåˆ†å¸ƒç›´æ–¹å›¾ï¼šæŸ¥çœ‹ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸Šå˜é‡ä¹‹é—´ä¸¤ä¸¤ç›¸äº’å…³ç³»çš„å¯è§†åŒ–å½¢å¼ï¼ˆé‡Œé¢åŒ…å«xã€yã€wã€hä¸¤ä¸¤ä¹‹é—´çš„åˆ†å¸ƒç›´æ–¹å›¾ï¼‰ã€‚
                    labels.jpgï¼šåŒ…å«ax[0]ç”»å‡ºclassesçš„å„ä¸ªç±»çš„åˆ†å¸ƒç›´æ–¹å›¾ï¼Œax[1]ç”»å‡ºæ‰€æœ‰çš„çœŸå®æ¡†ï¼›ax[2]ç”»å‡ºxyç›´æ–¹å›¾ï¼›ax[3]ç”»å‡ºwhç›´æ–¹å›¾ã€‚
        è¢«è°ƒç”¨ï¼šé€šå¸¸ä¼šç”¨åœ¨train.pyçš„è½½å…¥æ•°æ®datasetså’Œlabelsåï¼Œç»Ÿè®¡åˆ†ælabelsç›¸å…³åˆ†å¸ƒä¿¡æ¯ã€‚
    """
    """
       :params labels: æ•°æ®é›†çš„å…¨éƒ¨çœŸå®æ¡†æ ‡ç­¾  (num_targets, class+xywh)  (929, 5)
       :params names: æ•°æ®é›†çš„æ‰€æœ‰ç±»åˆ«å
       :params save_dir: runs\train\exp21
   """
    # plot dataset labels
    LOGGER.info(f"Plotting labels to {save_dir / 'labels.jpg'}... ")
    # c: classes (929)    b: boxes  xywh (4, 929)   .transpose() å°†(4, 929) -> (929, 4)
    c, b = labels[:, 0], labels[:, 1:].transpose()  # classes, boxes
    nc = int(c.max() + 1)  # ç±»åˆ«æ€»æ•° number of classes  80
    # pd.DataFrame: åˆ›å»ºDataFrame, ç±»ä¼¼äºä¸€ç§excel, è¡¨å¤´æ˜¯['x', 'y', 'width', 'height']  è¡¨æ ¼æ•°æ®: bä¸­æ•°æ®æŒ‰è¡Œä¾æ¬¡å­˜å‚¨
    x = pd.DataFrame(b.transpose(), columns=['x', 'y', 'width', 'height'])

    # 1ã€ç”»å‡ºlabelsçš„ xywh å„è‡ªè”åˆåˆ†å¸ƒç›´æ–¹å›¾  labels_correlogram.jpg
    # seaborn correlogram  seaborn.pairplot  å¤šå˜é‡è”åˆåˆ†å¸ƒå›¾: æŸ¥çœ‹ä¸¤ä¸ªæˆ–ä¸¤ä¸ªä»¥ä¸Šå˜é‡ä¹‹é—´ä¸¤ä¸¤ç›¸äº’å…³ç³»çš„å¯è§†åŒ–å½¢å¼
    # data: è”åˆåˆ†å¸ƒæ•°æ®x   diag_kind:è¡¨ç¤ºè”åˆåˆ†å¸ƒå›¾ä¸­å¯¹è§’çº¿å›¾çš„ç±»å‹   kind:è¡¨ç¤ºè”åˆåˆ†å¸ƒå›¾ä¸­éå¯¹è§’çº¿å›¾çš„ç±»å‹
    # corner: True è¡¨ç¤ºåªæ˜¾ç¤ºå·¦ä¸‹ä¾§ å› ä¸ºå·¦ä¸‹å’Œå³ä¸Šæ˜¯é‡å¤çš„   plot_kws,diag_kws: å¯ä»¥æ¥å—å­—å…¸çš„å‚æ•°ï¼Œå¯¹å›¾å½¢è¿›è¡Œå¾®è°ƒ
    # seaborn correlogram
    sn.pairplot(x, corner=True, diag_kind='auto', kind='hist', diag_kws=dict(bins=50), plot_kws=dict(pmax=0.9))
    plt.savefig(save_dir / 'labels_correlogram.jpg', dpi=200)   # ä¿å­˜labels_correlogram.jpg
    plt.close()

    # 2ã€ç”»å‡ºclassesçš„å„ä¸ªç±»çš„åˆ†å¸ƒç›´æ–¹å›¾ax[0], ç”»å‡ºæ‰€æœ‰çš„çœŸå®æ¡†ax[1], ç”»å‡ºxyç›´æ–¹å›¾ax[2], ç”»å‡ºwhç›´æ–¹å›¾ax[3] labels.jpg
    # matplotlib labels
    matplotlib.use('svg')  # faster
    # å°†æ•´ä¸ªfigureåˆ†æˆ2*2å››ä¸ªåŒºåŸŸ
    ax = plt.subplots(2, 2, figsize=(8, 8), tight_layout=True)[1].ravel()
    # ç¬¬ä¸€ä¸ªåŒºåŸŸax[1]ç”»å‡ºclassesçš„åˆ†å¸ƒç›´æ–¹å›¾
    y = ax[0].hist(c, bins=np.linspace(0, nc, nc + 1) - 0.5, rwidth=0.8)
    try:  # color histogram bars by class
        [y[2].patches[i].set_color([x / 255 for x in colors(i)]) for i in range(nc)]  # known issue #3195
    except Exception:
        pass
    ax[0].set_ylabel('instances')
    if 0 < len(names) < 30: # å°äº30ä¸ªç±»åˆ«å°±æŠŠæ‰€æœ‰çš„ç±»åˆ«åä½œä¸ºæ¨ªåæ ‡
        ax[0].set_xticks(range(len(names))) # è®¾ç½®åˆ»åº¦
        ax[0].set_xticklabels(names, rotation=90, fontsize=10)  # æ—‹è½¬90åº¦ è®¾ç½®æ¯ä¸ªåˆ»åº¦æ ‡ç­¾
    else:
        ax[0].set_xlabel('classes') # å¦‚æœç±»åˆ«æ•°å¤§äº30ä¸ª, å¯èƒ½å°±æ”¾ä¸ä¸‹å»äº†, æ‰€ä»¥åªæ˜¾ç¤ºxè½´label
    # ç¬¬ä¸‰ä¸ªåŒºåŸŸax[2]ç”»å‡ºxyç›´æ–¹å›¾     ç¬¬å››ä¸ªåŒºåŸŸax[3]ç”»å‡ºwhç›´æ–¹å›¾
    sn.histplot(x, x='x', y='y', ax=ax[2], bins=50, pmax=0.9)
    sn.histplot(x, x='width', y='height', ax=ax[3], bins=50, pmax=0.9)

    # rectangles
    # ç¬¬äºŒä¸ªåŒºåŸŸax[1]ç”»å‡ºæ‰€æœ‰çš„çœŸå®æ¡†
    labels[:, 1:3] = 0.5  # center
    labels[:, 1:] = xywh2xyxy(labels[:, 1:]) * 2000 # xyxy
    img = Image.fromarray(np.ones((2000, 2000, 3), dtype=np.uint8) * 255)   # åˆå§‹åŒ–ä¸€ä¸ªçª—å£
    for cls, *box in labels[:1000]: # æŠŠæ‰€æœ‰çš„æ¡†ç”»åœ¨imgçª—å£ä¸­
        ImageDraw.Draw(img).rectangle(box, width=1, outline=colors(cls))  # plot
    ax[1].imshow(img)
    ax[1].axis('off')   # ä¸è¦xyè½´

    # å»æ‰ä¸Šä¸‹å·¦å³åæ ‡ç³»(å»æ‰ä¸Šä¸‹å·¦å³è¾¹æ¡†)
    for a in [0, 1, 2, 3]:
        for s in ['top', 'right', 'left', 'bottom']:
            ax[a].spines[s].set_visible(False)

    plt.savefig(save_dir / 'labels.jpg', dpi=200)
    matplotlib.use('Agg')
    plt.close()


def plot_evolve(evolve_csv='path/to/evolve.csv'):  # from utils.plots import *; plot_evolve()
    # Plot evolve.csv hyp evolution results
    evolve_csv = Path(evolve_csv)
    data = pd.read_csv(evolve_csv)
    keys = [x.strip() for x in data.columns]
    x = data.values
    f = fitness(x)
    j = np.argmax(f)  # max fitness index
    plt.figure(figsize=(10, 12), tight_layout=True)
    matplotlib.rc('font', **{'size': 8})
    print(f'Best results from row {j} of {evolve_csv}:')
    for i, k in enumerate(keys[7:]):
        v = x[:, 7 + i]
        mu = v[j]  # best single result
        plt.subplot(6, 5, i + 1)
        plt.scatter(v, f, c=hist2d(v, f, 20), cmap='viridis', alpha=.8, edgecolors='none')
        plt.plot(mu, f.max(), 'k+', markersize=15)
        plt.title(f'{k} = {mu:.3g}', fontdict={'size': 9})  # limit to 40 characters
        if i % 5 != 0:
            plt.yticks([])
        print(f'{k:>15}: {mu:.3g}')
    f = evolve_csv.with_suffix('.png')  # filename
    plt.savefig(f, dpi=200)
    plt.close()
    print(f'Saved {f}')

# ==================================================================è¿™ä¸¤ä¸ªå‡½æ•°éƒ½æ˜¯ç”¨æ¥å¯¹result.txtä¸­çš„å„é¡¹æŒ‡æ ‡è¿›è¡Œå¯è§†åŒ–=================================================================

def plot_results(file='path/to/results.csv', dir=''):
    """
        å‡½æ•°åŠŸèƒ½ï¼šè¿™ä¸ªå‡½æ•°æ˜¯å°†è®­ç»ƒåçš„ç»“æœresults.csvä¸­ç›¸å…³çš„è®­ç»ƒæŒ‡æ ‡æ ‡ç”»åœ¨æŠ˜çº¿å›¾ä¸Šï¼ˆå…±10ä¸ªæŠ˜çº¿å›¾ï¼‰
                results.csvä¸­ä¸€è¡Œçš„å…ƒç´ åˆ†åˆ«æœ‰ï¼šå½“å‰epoch/æ€»epochs-1 ã€å½“å‰çš„æ˜¾å­˜å®¹é‡memã€boxå›å½’æŸå¤±ã€objç½®ä¿¡åº¦æŸå¤±ã€clsåˆ†ç±»æŸå¤±ã€è®­ç»ƒæ€»æŸå¤±ã€çœŸå®ç›®æ ‡æ•°é‡num_targetã€å›¾ç‰‡å°ºå¯¸img_shapeã€Precisionã€Recallã€map@0.5ã€map@0.5:0.95ã€æµ‹è¯•boxå›å½’æŸå¤±ã€æµ‹è¯•objç½®ä¿¡åº¦æŸã€æµ‹è¯•clsåˆ†ç±»æŸå¤±ã€‚
                results.csvä¸­ç”»å‡ºçš„æŒ‡æ ‡æœ‰ï¼šè®­ç»ƒå›å½’æŸå¤±Boxã€è®­ç»ƒç½®ä¿¡åº¦æŸå¤±Objectnessã€è®­ç»ƒåˆ†ç±»æŸå¤±Classificationã€Precisionã€Recallã€éªŒè¯å›å½’æŸå¤± val Boxã€éªŒè¯ç½®ä¿¡åº¦æŸå¤±val Objectnessã€éªŒè¯åˆ†ç±»æŸå¤±val Classificationã€mAP@0.5ã€mAP@0.5:0.95ã€‚
    """

    """
        :params save_dir: 'runs\train\exp22'
    """
    # Plot training results.csv. Usage: from utils.plots import *; plot_results('path/to/results.csv')
    save_dir = Path(file).parent if file else Path(dir)
     # å»ºé€ ä¸€ä¸ªfigure åˆ†å‰²æˆ2è¡Œ5åˆ—, ç”±10ä¸ªå°subplotsç»„æˆ
    fig, ax = plt.subplots(2, 5, figsize=(12, 6), tight_layout=True)
    ax = ax.ravel()  # å°†å¤šç»´æ•°ç»„é™ä¸ºä¸€ç»´
    files = list(save_dir.glob('results*.csv'))
    assert len(files), f'No results.csv files found in {save_dir.resolve()}, nothing to plot.'

    # è¯»å–filesæ–‡ä»¶æ•°æ®è¿›è¡Œå¯è§†åŒ–
    for fi, f in enumerate(files):
        try:
            # files åŸå§‹ä¸€è¡Œ: epoch/epochs - 1, memory, Box, Objectness, Classification, sum_loss, targets.shape[0], img_shape, Precision, Recall, map@0.5, map@0.5:0.95, Val Box, Val Objectness, Val Classification
            # åªä½¿ç”¨[2, 3, 4, 8, 9, 12, 13, 14, 10, 11]åˆ— (10, 1) åˆ†å¸ƒå¯¹åº” =>
            # [Box, Objectness, Classification, Precision, Recall, Val Box, Val Objectness, Val Classification, map@0.5, map@0.5:0.95]
            data = pd.read_csv(f)
            s = [x.strip() for x in data.columns]
            x = data.values[:, 0]
            for i, j in enumerate([1, 2, 3, 4, 5, 8, 9, 10, 6, 7]):
                y = data.values[:, j]
                # y[y == 0] = np.nan  # don't show zero values
                ax[i].plot(x, y, marker='.', label=f.stem, linewidth=2, markersize=8)   # ç”»å­å›¾
                ax[i].set_title(s[j], fontsize=12)
                # if j in [8, 9, 10]:  # share train and val loss y axes
                #     ax[i].get_shared_y_axes().join(ax[i], ax[i - 5])
        except Exception as e:
            LOGGER.info(f'Warning: Plotting error for {f}: {e}')
    ax[1].legend()
    fig.savefig(save_dir / 'results.png', dpi=200)   # ä¿å­˜results.png
    plt.close()

def butter_lowpass_filtfilt(data, cutoff=1500, fs=50000, order=5):
    """
        å‡½æ•°åŠŸèƒ½ï¼šä¸ºäº†é˜²æ­¢åœ¨è®­ç»ƒæ—¶æœ‰äº›æŒ‡æ ‡éå¸¸çš„æŠ–åŠ¨ï¼Œå¯¼è‡´ç”»å‡ºæ¥å¾ˆéš¾çœ‹ã€‚å½“dataå€¼æŠ–åŠ¨å¤ªå¤§, å°±å–dataçš„å¹³æ»‘æ›²çº¿ã€‚
    """
    from scipy.signal import butter, filtfilt

    # https://stackoverflow.com/questions/28536191/how-to-filter-smooth-with-scipy-numpy
    def butter_lowpass(cutoff, fs, order):
        nyq = 0.5 * fs
        normal_cutoff = cutoff / nyq
        return butter(order, normal_cutoff, btype='low', analog=False)

    b, a = butter_lowpass(cutoff, fs, order=order)
    return filtfilt(b, a, data)  # forward-backward filter

# =====================================================================================================================================================================




def profile_idetection(start=0, stop=0, labels=(), save_dir=''):
    """æ²¡ç”¨åˆ°
        Plot iDetection '*.txt' per-image logs
    """
    # Plot iDetection '*.txt' per-image logs. from utils.plots import *; profile_idetection()
    ax = plt.subplots(2, 4, figsize=(12, 6), tight_layout=True)[1].ravel()
    s = ['Images', 'Free Storage (GB)', 'RAM Usage (GB)', 'Battery', 'dt_raw (ms)', 'dt_smooth (ms)', 'real-world FPS']
    files = list(Path(save_dir).glob('frames*.txt'))
    for fi, f in enumerate(files):
        try:
            results = np.loadtxt(f, ndmin=2).T[:, 90:-30]  # clip first and last rows
            n = results.shape[1]  # number of rows
            x = np.arange(start, min(stop, n) if stop else n)
            results = results[:, x]
            t = (results[0] - results[0].min())  # set t0=0s
            results[0] = x
            for i, a in enumerate(ax):
                if i < len(results):
                    label = labels[fi] if len(labels) else f.stem.replace('frames_', '')
                    a.plot(t, results[i], marker='.', label=label, linewidth=1, markersize=5)
                    a.set_title(s[i])
                    a.set_xlabel('time (s)')
                    # if fi == len(files) - 1:
                    #     a.set_ylim(bottom=0)
                    for side in ['top', 'right']:
                        a.spines[side].set_visible(False)
                else:
                    a.remove()
        except Exception as e:
            print(f'Warning: Plotting error for {f}; {e}')
    ax[1].legend()
    plt.savefig(Path(save_dir) / 'idetection_profile.png', dpi=200)


def save_one_box(xyxy, im, file='image.jpg', gain=1.02, pad=10, square=False, BGR=False, save=True):
    """
        å‡½æ•°åŠŸèƒ½ï¼šå°†é¢„æµ‹åˆ°çš„ç›®æ ‡ä»åŸå›¾ä¸­æ‰£å‡ºæ¥ï¼Œå‰ªåˆ‡å¥½å¹¶ä¿å­˜ï¼Œä¼šåœ¨runs/detect/expnä¸‹ç”Ÿæˆcropsæ–‡ä»¶ï¼Œå°†å‰ªåˆ‡çš„å›¾ç‰‡ä¿å­˜åœ¨é‡Œé¢ã€‚
        ä¸»åŠ¨è°ƒç”¨ï¼šxyxy2xywhã€xywh2xyxyã€clip_coordsã€increment_pathç­‰å‡½æ•°ã€‚
        è¢«è°ƒç”¨ï¼šåœ¨detect.pyæ–‡ä»¶ä¸­  ç”±optçš„save-cropå‚æ•°æ§åˆ¶æ‰§ä¸æ‰§è¡Œ
    """

    """
        :params xyxy: é¢„æµ‹åˆ°çš„ç›®æ ‡æ¡†ä¿¡æ¯ list 4ä¸ªtensor x1 y1 x2 y2 å·¦ä¸Šè§’ + å³ä¸‹è§’
        :params im: åŸå›¾ç‰‡ éœ€è¦è£å‰ªçš„æ¡†ä»è¿™ä¸ªåŸå›¾ä¸Šè£å‰ª  nparray  (1080, 810, 3)
        :params file: runs\detect\exp\crops\dog\bus.jpg
        :params gain: 1.02 xyxyç¼©æ”¾å› å­
        :params pad: xyxy padä¸€ç‚¹ç‚¹è¾¹ç•Œæ¡† è£å‰ªå‡ºæ¥ä¼šæ›´å¥½çœ‹
        :params square: æ˜¯å¦éœ€è¦å°†xyxyæ”¾ç¼©æˆæ­£æ–¹å½¢
        :params BGR: ä¿å­˜çš„å›¾ç‰‡æ˜¯BGRè¿˜æ˜¯RGB
        :params save: æ˜¯å¦è¦ä¿å­˜å‰ªåˆ‡çš„ç›®æ ‡æ¡†
    """
    # Save image crop as {file} with crop size multiple {gain} and {pad} pixels. Save and/or return crop
    xyxy = torch.tensor(xyxy).view(-1, 4)
    b = xyxy2xywh(xyxy)  # boxes
    if square:  # ä¸€èˆ¬ä¸éœ€è¦rectangle to square
        b[:, 2:] = b[:, 2:].max(1)[0].unsqueeze(1)  # attempt rectangle to square
        # box wh * gain + pad  box*gainå†åŠ ç‚¹pad è£å‰ªå‡ºæ¥æ¡†æ›´å¥½çœ‹
    b[:, 2:] = b[:, 2:] * gain + pad  # box wh * gain + pad
    xyxy = xywh2xyxy(b).long()
    # å°†boxesçš„åæ ‡(x1y1x2y2 å·¦ä¸Šè§’å³ä¸‹è§’)é™å®šåœ¨å›¾åƒçš„å°ºå¯¸(img_shape hw)å†…
    clip_coords(xyxy, im.shape)
    # crop: å‰ªåˆ‡çš„ç›®æ ‡æ¡†hw
    crop = im[int(xyxy[0, 1]):int(xyxy[0, 3]), int(xyxy[0, 0]):int(xyxy[0, 2]), ::(1 if BGR else -1)]
    if save:
        # ä¿å­˜å‰ªåˆ‡çš„ç›®æ ‡æ¡†
        file.parent.mkdir(parents=True, exist_ok=True)  # make directory
        cv2.imwrite(str(increment_path(file).with_suffix('.jpg')), crop)
    return crop
