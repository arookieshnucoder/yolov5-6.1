# YOLOv5 ğŸš€ by Ultralytics, GPL-3.0 license
"""
    Dataloaders and dataset utils
    è¿™ä¸ªæ–‡ä»¶ä¸»è¦æ˜¯è¿›è¡Œæ•°æ®å¢å¼ºæ“ä½œã€‚
"""

"""
    Â·æ³¨é‡Šæ¥æºäºå„ä½å¤§ä½¬çš„è§†é¢‘+åšå®¢ï¼Œæ”¶é›†ä¸æ˜“ï¼Œç¥ä½ æ—©æ—¥å‡ºsciï¼
    Â·ç§‰æŒå¼€æºç²¾ç¥ï¼å–ä¹‹äºå¤§ä½¬ï¼Œç”¨ä¹‹äºå„ä½ï¼
    Â·@Dragon AI 
"""

import glob # pythonè‡ªå·±å¸¦çš„ä¸€ä¸ªæ–‡ä»¶æ“ä½œç›¸å…³æ¨¡å— æŸ¥æ‰¾ç¬¦åˆè‡ªå·±ç›®çš„çš„æ–‡ä»¶(å¦‚æ¨¡ç³ŠåŒ¹é…)
import hashlib  # å“ˆå¸Œæ¨¡å— æä¾›äº†å¤šç§å®‰å…¨æ–¹ä¾¿çš„hashæ–¹æ³•
import json # jsonæ–‡ä»¶æ“ä½œæ¨¡å—
import math # æ•°å­¦å…¬å¼æ¨¡å—
import os   # ä¸æ“ä½œç³»ç»Ÿè¿›è¡Œäº¤äº’çš„æ¨¡å— åŒ…å«æ–‡ä»¶è·¯å¾„æ“ä½œå’Œè§£æ
import random
import shutil    # æ–‡ä»¶å¤¹ã€å‹ç¼©åŒ…å¤„ç†æ¨¡å—
import time # æ—¶é—´æ¨¡å— æ›´åº•å±‚
from itertools import repeat     # å¤åˆ¶æ¨¡å—
from multiprocessing.pool import Pool, ThreadPool    # å¤šçº¿ç¨‹æ¨¡å— çº¿ç¨‹æ± 
from pathlib import Path    # Pathå°†strè½¬æ¢ä¸ºPathå¯¹è±¡ ä½¿å­—ç¬¦ä¸²è·¯å¾„æ˜“äºæ“ä½œçš„æ¨¡å—
from threading import Thread     # å¤šçº¿ç¨‹æ“ä½œæ¨¡å—
from zipfile import ZipFile

import cv2   # opencvæ¨¡å—
import numpy as np   # numpyçŸ©é˜µæ“ä½œæ¨¡å—
import torch
import torch.nn.functional as F # PyTorchå‡½æ•°æ¥å£ å°è£…äº†å¾ˆå¤šå·ç§¯ã€æ± åŒ–ç­‰å‡½æ•°
import yaml  # yamlæ–‡ä»¶æ“ä½œæ¨¡å—
from PIL import ExifTags, Image, ImageOps    # å›¾ç‰‡ã€ç›¸æœºæ“ä½œæ¨¡å—
from torch.utils.data import DataLoader, Dataset, dataloader, distributed   # è‡ªå®šä¹‰æ•°æ®é›†æ¨¡å—
from tqdm import tqdm   # è¿›åº¦æ¡æ¨¡å—

from utils.augmentations import Albumentations, augment_hsv, copy_paste, letterbox, mixup, random_perspective
from utils.general import (DATASETS_DIR, LOGGER, NUM_THREADS, check_dataset, check_requirements, check_yaml, clean_str,
                           segments2boxes, xyn2xy, xywh2xyxy, xywhn2xyxy, xyxy2xywhn)
from utils.torch_utils import torch_distributed_zero_first

# Parameters
HELP_URL = 'https://github.com/ultralytics/yolov5/wiki/Train-Custom-Data'
IMG_FORMATS = ['bmp', 'dng', 'jpeg', 'jpg', 'mpo', 'png', 'tif', 'tiff', 'webp']  # include image suffixes
VID_FORMATS = ['asf', 'avi', 'gif', 'm4v', 'mkv', 'mov', 'mp4', 'mpeg', 'mpg', 'wmv']  # include video suffixes

# ---------------------------------------- 1ã€ç›¸æœºè®¾ç½® ----------------------------------------
# ç›¸æœºç›¸å…³è®¾ç½®ï¼Œå½“ä½¿ç”¨ç›¸æœºé‡‡æ ·æ—¶æ‰ä¼šä½¿ç”¨
# ä¸“é—¨ä¸ºæ•°ç ç›¸æœºçš„ç…§ç‰‡è€Œè®¾å®š  å¯ä»¥è®°å½•æ•°ç ç…§ç‰‡çš„å±æ€§ä¿¡æ¯å’Œæ‹æ‘„æ•°æ®
for orientation in ExifTags.TAGS.keys():
    if ExifTags.TAGS[orientation] == 'Orientation':
        break

def get_hash(paths):
    # è¿”å›æ–‡ä»¶åˆ—è¡¨çš„hashå€¼
    # Returns a single hash value of a list of paths (files or dirs)
    size = sum(os.path.getsize(p) for p in paths if os.path.exists(p))  # sizes
    h = hashlib.md5(str(size).encode())  # hash sizes
    h.update(''.join(paths).encode())  # hash paths
    return h.hexdigest()  # return hash


def exif_size(img):
    # è·å–æ•°ç ç›¸æœºçš„å›¾ç‰‡å®½é«˜ä¿¡æ¯  å¹¶ä¸”åˆ¤æ–­æ˜¯å¦éœ€è¦æ—‹è½¬ï¼ˆæ•°ç ç›¸æœºå¯ä»¥å¤šè§’åº¦æ‹æ‘„ï¼‰
    # Returns exif-corrected PIL size
    s = img.size  # (width, height)
    try:
        rotation = dict(img._getexif().items())[orientation]
        if rotation == 6:  # rotation 270
            s = (s[1], s[0])
        elif rotation == 8:  # rotation 90
            s = (s[1], s[0])
    except Exception:
        pass

    return s


def exif_transpose(image):
    """
    Transpose a PIL image accordingly if it has an EXIF Orientation tag.
    Inplace version of https://github.com/python-pillow/Pillow/blob/master/src/PIL/ImageOps.py exif_transpose()

    :param image: The image to transpose.
    :return: An image.
    """
    exif = image.getexif()
    orientation = exif.get(0x0112, 1)  # default 1
    if orientation > 1:
        method = {2: Image.FLIP_LEFT_RIGHT,
                  3: Image.ROTATE_180,
                  4: Image.FLIP_TOP_BOTTOM,
                  5: Image.TRANSPOSE,
                  6: Image.ROTATE_270,
                  7: Image.TRANSVERSE,
                  8: Image.ROTATE_90,
                  }.get(orientation)
        if method is not None:
            image = image.transpose(method)
            del exif[0x0112]
            image.info["exif"] = exif.tobytes()
    return image


def create_dataloader(path, imgsz, batch_size, stride, single_cls=False, hyp=None, augment=False, cache=False, pad=0.0,
                      rect=False, rank=-1, workers=8, image_weights=False, quad=False, prefix='', shuffle=False):
    """
        è¿™ä¸ªå‡½æ•°ä¼šåœ¨train.pyä¸­è¢«è°ƒç”¨ï¼Œç”¨äºç”ŸæˆTrainloader, datasetï¼Œtestloaderï¼š

        è‡ªå®šä¹‰dataloaderå‡½æ•°:    è°ƒç”¨LoadImagesAndLabelsè·å–æ•°æ®é›†dataset(åŒ…æ‹¬æ•°æ®å¢å¼º) + è°ƒç”¨åˆ†å¸ƒå¼é‡‡æ ·å™¨DistributedSampler
                                    + è‡ªå®šä¹‰InfiniteDataLoader è¿›è¡Œæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ® + è·å–dataloaderã€‚

        å…³é”®æ ¸å¿ƒæ˜¯LoadImagesAndLabels()ï¼Œè¿™ä¸ªæ–‡ä»¶çš„åé¢æ‰€æœ‰ä»£ç éƒ½æ˜¯å›´ç»•è¿™ä¸ªæ¨¡å—è¿›è¡Œçš„ã€‚

        :param path: å›¾ç‰‡æ•°æ®åŠ è½½è·¯å¾„ train/test  å¦‚: ../datasets/VOC/images/train2007
        :param imgsz: train/testå›¾ç‰‡å°ºå¯¸ï¼ˆæ•°æ®å¢å¼ºåå¤§å°ï¼‰ 640
        :param batch_size: batch size å¤§å° 8/16/32
        :param stride: æ¨¡å‹æœ€å¤§stride=32   [32 16 8]
        :param single_cls: æ•°æ®é›†æ˜¯å¦æ˜¯å•ç±»åˆ« é»˜è®¤False
        :param hyp: è¶…å‚åˆ—è¡¨dict ç½‘ç»œè®­ç»ƒæ—¶çš„ä¸€äº›è¶…å‚æ•°ï¼ŒåŒ…æ‹¬å­¦ä¹ ç‡ç­‰ï¼Œè¿™é‡Œä¸»è¦ç”¨åˆ°é‡Œé¢ä¸€äº›å…³äºæ•°æ®å¢å¼º(æ—‹è½¬ã€å¹³ç§»ç­‰)çš„ç³»æ•°
        :param augment: æ˜¯å¦è¦è¿›è¡Œæ•°æ®å¢å¼º  True
        :param cache: æ˜¯å¦cache_images False
        :param pad: è®¾ç½®çŸ©å½¢è®­ç»ƒçš„shapeæ—¶è¿›è¡Œçš„å¡«å…… é»˜è®¤0.0
        :param rect: æ˜¯å¦å¼€å¯çŸ©å½¢train/test  é»˜è®¤è®­ç»ƒé›†å…³é—­ éªŒè¯é›†å¼€å¯
        :param rank:  å¤šå¡è®­ç»ƒæ—¶çš„è¿›ç¨‹ç¼–å· rankä¸ºè¿›ç¨‹ç¼–å·  -1ä¸”gpu=1æ—¶ä¸è¿›è¡Œåˆ†å¸ƒå¼  -1ä¸”å¤šå—gpuä½¿ç”¨DataParallelæ¨¡å¼  é»˜è®¤-1
        :param workers: dataloaderçš„numworks åŠ è½½æ•°æ®æ—¶çš„cpuè¿›ç¨‹æ•°
        :param image_weights: è®­ç»ƒæ—¶æ˜¯å¦æ ¹æ®å›¾ç‰‡æ ·æœ¬çœŸå®æ¡†åˆ†å¸ƒæƒé‡æ¥é€‰æ‹©å›¾ç‰‡  é»˜è®¤False
        :param quad: dataloaderå–æ•°æ®æ—¶, æ˜¯å¦ä½¿ç”¨collate_fn4ä»£æ›¿collate_fn  é»˜è®¤False
        :param prefix: æ˜¾ç¤ºä¿¡æ¯   ä¸€ä¸ªæ ‡å¿—ï¼Œå¤šä¸ºtrain/valï¼Œå¤„ç†æ ‡ç­¾æ—¶ä¿å­˜cacheæ–‡ä»¶ä¼šç”¨åˆ°
        """
    if rect and shuffle:
        LOGGER.warning('WARNING: --rect is incompatible with DataLoader shuffle, setting shuffle=False')
        shuffle = False

    # Make sure only the first process in DDP process the dataset first, and the following others can use the cache
    # ä¸»è¿›ç¨‹å®ç°æ•°æ®çš„é¢„è¯»å–å¹¶ç¼“å­˜ï¼Œç„¶åå…¶å®ƒå­è¿›ç¨‹åˆ™ä»ç¼“å­˜ä¸­è¯»å–æ•°æ®å¹¶è¿›è¡Œä¸€ç³»åˆ—è¿ç®—ã€‚
    # ä¸ºäº†å®Œæˆæ•°æ®çš„æ­£å¸¸åŒæ­¥, yolov5åŸºäºtorch.distributed.barrier()å‡½æ•°å®ç°äº†ä¸Šä¸‹æ–‡ç®¡ç†å™¨
    with torch_distributed_zero_first(rank):  # init dataset *.cache only once if DDP
        # è½½å…¥æ–‡ä»¶æ•°æ®(å¢å¼ºæ•°æ®é›†)
        # Todo LoadImagesAndLabelså…¥å£
        dataset = LoadImagesAndLabels(path, imgsz, batch_size,
                                      augment=augment,  # augmentation
                                      hyp=hyp,  # hyperparameters
                                      rect=rect,  # rectangular batches
                                      cache_images=cache, # ç¼“å­˜ï¼šä½¿å›¾ç‰‡ä¸ä¾¿ç­¾è¿›è¡Œç¼“å­˜ï¼Œä½¿å¾—ç¬¬äºŒæ¬¡è®­ç»ƒæ—¶æ›´å¿«è¯»å–
                                      single_cls=single_cls, # å•ç±»åˆ«æ‰ä½¿ç”¨
                                      stride=int(stride), # ä»è¾“å…¥åˆ°è¾“å‡ºé™é‡‡æ ·çš„æ¯”ä¾‹
                                      pad=pad,  # å›¾ç‰‡å¤§å°ä¸åŒæ—¶ï¼Œè¾¹è§’å¡«å……
                                      image_weights=image_weights,
                                      prefix=prefix)

    batch_size = min(batch_size, len(dataset))
    nd = torch.cuda.device_count()  # number of CUDA devices
    nw = min([os.cpu_count() // max(nd, 1), batch_size if batch_size > 1 else 0, workers])  # number of workers
    # åˆ†å¸ƒå¼é‡‡æ ·å™¨DistributedSampler
    sampler = None if rank == -1 else distributed.DistributedSampler(dataset, shuffle=shuffle)
    # ä½¿ç”¨InfiniteDataLoaderå’Œ_RepeatSampleræ¥å¯¹DataLoaderè¿›è¡Œå°è£…, ä»£æ›¿åŸå…ˆçš„DataLoader, èƒ½å¤Ÿæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ®
    loader = DataLoader if image_weights else InfiniteDataLoader  # only DataLoader allows for attribute updates
    return loader(dataset,
                  batch_size=batch_size,
                  shuffle=shuffle and sampler is None,
                  # num_workers=nw,
                  num_workers=0,
                  sampler=sampler,
                  pin_memory=True,
                  collate_fn=LoadImagesAndLabels.collate_fn4 if quad else LoadImagesAndLabels.collate_fn), dataset


class InfiniteDataLoader(dataloader.DataLoader):
    """
        å½“image_weights=Falseæ—¶ï¼ˆä¸æ ¹æ®å›¾ç‰‡æ ·æœ¬çœŸå®æ¡†åˆ†å¸ƒæƒé‡æ¥é€‰æ‹©å›¾ç‰‡ï¼‰å°±ä¼šè°ƒç”¨è¿™ä¸¤ä¸ªå‡½æ•°è¿›è¡Œè‡ªå®šä¹‰DataLoaderï¼Œè¿›è¡ŒæŒç»­æ€§é‡‡æ ·ã€‚
        åœ¨ä¸Šé¢çš„create_dataloaderæ¨¡å—ä¸­è¢«è°ƒç”¨ã€‚

        https://github.com/ultralytics/yolov5/pull/876
        ä½¿ç”¨InfiniteDataLoaderå’Œ_RepeatSampleræ¥å¯¹DataLoaderè¿›è¡Œå°è£…, ä»£æ›¿åŸå…ˆçš„DataLoader, èƒ½å¤Ÿæ°¸ä¹…æŒç»­çš„é‡‡æ ·æ•°æ®
        Uses same syntax as vanilla DataLoader
    """

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        # è°ƒç”¨_RepeatSamplerè¿›è¡ŒæŒç»­é‡‡æ ·
        object.__setattr__(self, 'batch_sampler', _RepeatSampler(self.batch_sampler))
        self.iterator = super().__iter__()

    def __len__(self):
        return len(self.batch_sampler.sampler)

    def __iter__(self):
        for i in range(len(self)):
            yield next(self.iterator)


class _RepeatSampler:
    """ Sampler that repeats forever
    è¿™éƒ¨åˆ†æ˜¯è¿›è¡ŒæŒç»­é‡‡æ ·
    Args:
        sampler (Sampler)
    """

    def __init__(self, sampler):
        self.sampler = sampler

    def __iter__(self):
        while True:
            yield from iter(self.sampler)


class LoadImages:
    # YOLOv5 image/video dataloader, i.e. `python detect.py --source image.jpg/vid.mp4`
    def __init__(self, path, img_size=640, stride=32, auto=True):
        p = str(Path(path).resolve())  # os-agnostic absolute path
        if '*' in p:
            files = sorted(glob.glob(p, recursive=True))  # glob
        elif os.path.isdir(p):
            files = sorted(glob.glob(os.path.join(p, '*.*')))  # dir
        elif os.path.isfile(p):
            files = [p]  # files
        else:
            raise Exception(f'ERROR: {p} does not exist')

        images = [x for x in files if x.split('.')[-1].lower() in IMG_FORMATS]
        videos = [x for x in files if x.split('.')[-1].lower() in VID_FORMATS]
        ni, nv = len(images), len(videos)

        self.img_size = img_size
        self.stride = stride
        self.files = images + videos
        self.nf = ni + nv  # number of files
        self.video_flag = [False] * ni + [True] * nv
        self.mode = 'image'
        self.auto = auto
        if any(videos):
            self.new_video(videos[0])  # new video
        else:
            self.cap = None
        assert self.nf > 0, f'No images or videos found in {p}. ' \
                            f'Supported formats are:\nimages: {IMG_FORMATS}\nvideos: {VID_FORMATS}'

    def __iter__(self):
        self.count = 0
        return self

    def __next__(self):
        if self.count == self.nf:
            raise StopIteration
        path = self.files[self.count]

        if self.video_flag[self.count]:
            # Read video
            self.mode = 'video'
            ret_val, img0 = self.cap.read()
            while not ret_val:
                self.count += 1
                self.cap.release()
                if self.count == self.nf:  # last video
                    raise StopIteration
                else:
                    path = self.files[self.count]
                    self.new_video(path)
                    ret_val, img0 = self.cap.read()

            self.frame += 1
            s = f'video {self.count + 1}/{self.nf} ({self.frame}/{self.frames}) {path}: '

        else:
            # Read image
            self.count += 1
            img0 = cv2.imread(path)  # BGR
            assert img0 is not None, f'Image Not Found {path}'
            s = f'image {self.count}/{self.nf} {path}: '

        # Padded resize
        img = letterbox(img0, self.img_size, stride=self.stride, auto=self.auto)[0]

        # Convert
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        img = np.ascontiguousarray(img)

        return path, img, img0, self.cap, s

    def new_video(self, path):
        self.frame = 0
        self.cap = cv2.VideoCapture(path)
        self.frames = int(self.cap.get(cv2.CAP_PROP_FRAME_COUNT))

    def __len__(self):
        return self.nf  # number of files


class LoadWebcam:  # for inference
    """
        ç”¨åˆ°å¾ˆå°‘ load webç½‘é¡µä¸­çš„æ•°æ®
    """
    # YOLOv5 local webcam dataloader, i.e. `python detect.py --source 0`
    def __init__(self, pipe='0', img_size=640, stride=32):
        self.img_size = img_size
        self.stride = stride
        self.pipe = eval(pipe) if pipe.isnumeric() else pipe
        self.cap = cv2.VideoCapture(self.pipe)  # video capture object
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 3)  # set buffer size

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        if cv2.waitKey(1) == ord('q'):  # q to quit
            self.cap.release()
            cv2.destroyAllWindows()
            raise StopIteration

        # Read frame
        ret_val, img0 = self.cap.read()
        img0 = cv2.flip(img0, 1)  # flip left-right

        # Print
        assert ret_val, f'Camera Error {self.pipe}'
        img_path = 'webcam.jpg'
        s = f'webcam {self.count}: '

        # Padded resize
        img = letterbox(img0, self.img_size, stride=self.stride)[0]

        # Convert
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        img = np.ascontiguousarray(img)

        return img_path, img, img0, None, s

    def __len__(self):
        return 0


class LoadStreams:
    """
        load æ–‡ä»¶å¤¹ä¸­è§†é¢‘æµ
        multiple IP or RTSP cameras
        å®šä¹‰è¿­ä»£å™¨ ç”¨äºdetect.py
    """
    # YOLOv5 streamloader, i.e. `python detect.py --source 'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP streams`
    def __init__(self, sources='streams.txt', img_size=640, stride=32, auto=True):
        self.mode = 'stream'     # åˆå§‹åŒ–modeä¸ºimages
        self.img_size = img_size
        self.stride = stride      # æœ€å¤§ä¸‹é‡‡æ ·æ­¥é•¿

        # å¦‚æœsourcesä¸ºä¸€ä¸ªä¿å­˜äº†å¤šä¸ªè§†é¢‘æµçš„æ–‡ä»¶  è·å–æ¯ä¸€ä¸ªè§†é¢‘æµï¼Œä¿å­˜ä¸ºä¸€ä¸ªåˆ—è¡¨
        if os.path.isfile(sources):
            with open(sources) as f:
                sources = [x.strip() for x in f.read().strip().splitlines() if len(x.strip())]
        else:
            # åä¹‹ï¼Œåªæœ‰ä¸€ä¸ªè§†é¢‘æµæ–‡ä»¶å°±ç›´æ¥ä¿å­˜
            sources = [sources]

        n = len(sources)    # è§†é¢‘æµä¸ªæ•°
        # åˆå§‹åŒ–å›¾ç‰‡ fps æ€»å¸§æ•° çº¿ç¨‹æ•°
        self.imgs, self.fps, self.frames, self.threads = [None] * n, [0] * n, [0] * n, [None] * n
        self.sources = [clean_str(x) for x in sources]  # clean source names for later
        self.auto = auto

        # éå†æ¯ä¸€ä¸ªè§†é¢‘æµ
        for i, s in enumerate(sources):  # index, source
            # Start thread to read frames from video stream
            # æ‰“å°å½“å‰è§†é¢‘index/æ€»è§†é¢‘æ•°/è§†é¢‘æµåœ°å€
            st = f'{i + 1}/{n}: {s}... '
            if 'youtube.com/' in s or 'youtu.be/' in s:  # if source is YouTube video
                check_requirements(('pafy', 'youtube_dl==2020.12.2'))
                import pafy
                s = pafy.new(s).getbest(preftype="mp4").url  # YouTube URL
            s = eval(s) if s.isnumeric() else s  # i.e. s = '0' local webcam
            # s='0'æ‰“å¼€æœ¬åœ°æ‘„åƒå¤´ï¼Œå¦åˆ™æ‰“å¼€è§†é¢‘æµåœ°å€
            cap = cv2.VideoCapture(s)
            assert cap.isOpened(), f'{st}Failed to open {s}'
            # è·å–è§†é¢‘çš„å®½å’Œé•¿
            w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
            h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

            fps = cap.get(cv2.CAP_PROP_FPS)  # warning: may return 0 or nan
            # å¸§æ•°
            self.frames[i] = max(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), 0) or float('inf')  # infinite stream fallback
            # è·å–è§†é¢‘çš„å¸§ç‡
            self.fps[i] = max((fps if math.isfinite(fps) else 0) % 100, 0) or 30  # 30 FPS fallback

            # è¯»å–å½“å‰ç”»é¢
            _, self.imgs[i] = cap.read()  # guarantee first frame
            # åˆ›å»ºå¤šçº¿ç¨‹è¯»å–è§†é¢‘æµï¼Œdaemonè¡¨ç¤ºä¸»çº¿ç¨‹ç»“æŸæ—¶å­çº¿ç¨‹ä¹Ÿç»“æŸ
            self.threads[i] = Thread(target=self.update, args=([i, cap, s]), daemon=True)
            LOGGER.info(f"{st} Success ({self.frames[i]} frames {w}x{h} at {self.fps[i]:.2f} FPS)")
            self.threads[i].start()
        LOGGER.info('')  # newline

        # check for common shapes
        # è·å–è¿›è¡Œresize+padä¹‹åçš„shapeï¼Œletterboxå‡½æ•°é»˜è®¤(å‚æ•°auto=True)æ˜¯æŒ‰ç…§çŸ©å½¢æ¨ç†è¿›è¡Œå¡«å……
        s = np.stack([letterbox(x, self.img_size, stride=self.stride, auto=self.auto)[0].shape for x in self.imgs])
        self.rect = np.unique(s, axis=0).shape[0] == 1  # rect inference if all shapes equal
        if not self.rect:
            LOGGER.warning('WARNING: Stream shapes differ. For optimal performance supply similarly-shaped streams.')

    def update(self, i, cap, stream):
        # Read stream `i` frames in daemon thread
        n, f, read = 0, self.frames[i], 1  # frame number, frame array, inference every 'read' frame
        while cap.isOpened() and n < f:
            n += 1
            # _, self.imgs[index] = cap.read()
            cap.grab()
            # æ¯4å¸§è¯»å–ä¸€æ¬¡
            if n % read == 0:
                success, im = cap.retrieve()
                if success:
                    self.imgs[i] = im
                else:
                    LOGGER.warning('WARNING: Video stream unresponsive, please check your IP camera connection.')
                    self.imgs[i] = np.zeros_like(self.imgs[i])
                    cap.open(stream)  # re-open stream if signal was lost
            time.sleep(1 / self.fps[i])  # wait time

    def __iter__(self):
        self.count = -1
        return self

    def __next__(self):
        self.count += 1
        if not all(x.is_alive() for x in self.threads) or cv2.waitKey(1) == ord('q'):  # q to quit
            cv2.destroyAllWindows()
            raise StopIteration

        # Letterbox
        img0 = self.imgs.copy()
        img = [letterbox(x, self.img_size, stride=self.stride, auto=self.rect and self.auto)[0] for x in img0]

        # Stack  å°†è¯»å–çš„å›¾ç‰‡æ‹¼æ¥åˆ°ä¸€èµ·
        img = np.stack(img, 0)

        # Convert
        img = img[..., ::-1].transpose((0, 3, 1, 2))  # BGR to RGB, BHWC to BCHW
        img = np.ascontiguousarray(img)

        return self.sources, img, img0, None, ''

    def __len__(self):
        return len(self.sources)  # 1E12 frames = 32 streams at 30 FPS for 30 years


def img2label_paths(img_paths):
    """
        è¿™ä¸ªæ–‡ä»¶æ˜¯æ ¹æ®æ•°æ®é›†ä¸­æ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„æ‰¾åˆ°æ•°æ®é›†ä¸­æ‰€æœ‰labelså¯¹åº”çš„è·¯å¾„ã€‚
        ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__init__å‡½æ•°ä¸­ã€‚

        :params img_paths: {list: 50}  æ•´ä¸ªæ•°æ®é›†çš„å›¾ç‰‡ç›¸å¯¹è·¯å¾„  ä¾‹å¦‚: '..\\datasets\\VOC\\images\\train2007\\000012.jpg'
                                                        =>   '..\\datasets\\VOC\\labels\\train2007\\000012.jpg'
    """
    # Define label paths as a function of image paths
    # å› ä¸ºpythonæ˜¯è·¨å¹³å°çš„,åœ¨Windowsä¸Š,æ–‡ä»¶çš„è·¯å¾„åˆ†éš”ç¬¦æ˜¯'\',åœ¨Linuxä¸Šæ˜¯'/'
    # ä¸ºäº†è®©ä»£ç åœ¨ä¸åŒçš„å¹³å°ä¸Šéƒ½èƒ½è¿è¡Œï¼Œé‚£ä¹ˆè·¯å¾„åº”è¯¥å†™'\'è¿˜æ˜¯'/'å‘¢ï¼Ÿ os.sepæ ¹æ®ä½ æ‰€å¤„çš„å¹³å°, è‡ªåŠ¨é‡‡ç”¨ç›¸åº”çš„åˆ†éš”ç¬¦å·
    # sa: '\\images\\'    sb: '\\labels\\'
    sa, sb = os.sep + 'images' + os.sep, os.sep + 'labels' + os.sep  # /images/, /labels/ substrings
    # æŠŠimg_pathsä¸­æ‰€ä»¥å›¾ç‰‡è·¯å¾„ä¸­çš„imagesæ›¿æ¢ä¸ºlabels
    return [sb.join(x.rsplit(sa, 1)).rsplit('.', 1)[0] + '.txt' for x in img_paths]


class LoadImagesAndLabels(Dataset):
    """
        è¿™ä¸ªéƒ¨åˆ†æ˜¯æ•°æ®è½½å…¥ï¼ˆæ•°æ®å¢å¼ºï¼‰éƒ¨åˆ†ï¼Œä¹Ÿå°±æ˜¯è‡ªå®šä¹‰æ•°æ®é›†éƒ¨åˆ†ï¼Œç»§æ‰¿è‡ªDatasetï¼Œéœ€è¦é‡å†™__init__,__getitem()__ç­‰æŠ½è±¡æ–¹æ³•ï¼Œ
        å¦å¤–ç›®æ ‡æ£€æµ‹ä¸€èˆ¬è¿˜éœ€è¦é‡å†™collate_fnå‡½æ•°ã€‚æ‰€ä»¥ï¼Œç†è§£è¿™ä¸‰ä¸ªå‡½æ•°æ˜¯ç†è§£æ•°æ®å¢å¼ºï¼ˆæ•°æ®è½½å…¥ï¼‰çš„é‡ä¸­ä¹‹é‡ã€‚

    """
    # YOLOv5 train_loader/val_loader, loads images and labels for training and validation
    cache_version = 0.6  # dataset labels *.cache version

    def __init__(self, path, img_size=640, batch_size=16, augment=False, hyp=None, rect=False, image_weights=False,
                 cache_images=False, single_cls=False, stride=32, pad=0.0, prefix=''):
        """
                åˆå§‹åŒ–è¿‡ç¨‹å¹¶æ²¡æœ‰ä»€ä¹ˆå®è´¨æ€§çš„æ“ä½œ,æ›´å¤šæ˜¯ä¸€ä¸ªå®šä¹‰å‚æ•°çš„è¿‡ç¨‹ï¼ˆselfå‚æ•°ï¼‰,ä»¥ä¾¿åœ¨__getitem()__ä¸­è¿›è¡Œæ•°æ®å¢å¼ºæ“ä½œ,
                æ‰€ä»¥è¿™éƒ¨åˆ†ä»£ç åªéœ€è¦æŠ“ä½selfä¸­çš„å„ä¸ªå˜é‡çš„å«ä¹‰å°±ç®—å·®ä¸å¤šäº†

                __init__()ä¸»è¦æ­¥éª¤
                        1ã€èµ‹å€¼ä¸€äº›åŸºç¡€çš„selfå˜é‡ ç”¨äºåé¢åœ¨__getitem__ä¸­è°ƒç”¨
                        2ã€å¾—åˆ°pathè·¯å¾„ä¸‹çš„æ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„self.img_files
                        3ã€æ ¹æ®imgsè·¯å¾„æ‰¾åˆ°labelsçš„è·¯å¾„self.label_files
                        4ã€cache label
                        5ã€Read cache ç”Ÿæˆself.labelsã€self.shapesã€self.img_filesã€self.label_filesã€self.batchã€self.nã€self.indicesç­‰å˜é‡
                        6ã€ä¸ºRectangular Trainingä½œå‡†å¤‡: ç”Ÿæˆself.batch_shapes
                        7ã€æ˜¯å¦éœ€è¦cache image(ä¸€èˆ¬ä¸éœ€è¦ï¼Œå¤ªå¤§äº†)

                self.img_files: {list: N} å­˜æ”¾ç€æ•´ä¸ªæ•°æ®é›†å›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„
                self.label_files: {list: N} å­˜æ”¾ç€æ•´ä¸ªæ•°æ®é›†å›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„
                cache label -> verify_image_label
                self.labels: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  labelså­˜å‚¨çš„labelå°±éƒ½æ˜¯åŸå§‹label(éƒ½æ˜¯æ­£å¸¸çš„çŸ©å½¢label)
                             å¦åˆ™å°†æ‰€æœ‰å›¾ç‰‡æ­£å¸¸gtçš„labelå­˜å…¥labels ä¸æ­£å¸¸gt(å­˜åœ¨ä¸€ä¸ªå¤šè¾¹å½¢)ç»è¿‡segments2boxesè½¬æ¢ä¸ºæ­£å¸¸çš„çŸ©å½¢label
                self.shapes: æ‰€æœ‰å›¾ç‰‡çš„shape
                self.segments: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  self.segments=None
                               å¦åˆ™å­˜å‚¨æ•°æ®é›†ä¸­æ‰€æœ‰å­˜åœ¨å¤šè¾¹å½¢gtçš„å›¾ç‰‡çš„æ‰€æœ‰åŸå§‹label(è‚¯å®šæœ‰å¤šè¾¹å½¢label ä¹Ÿå¯èƒ½æœ‰çŸ©å½¢æ­£å¸¸label æœªçŸ¥æ•°)
                self.batch: è®°è½½ç€æ¯å¼ å›¾ç‰‡å±äºå“ªä¸ªbatch
                self.n: æ•°æ®é›†ä¸­æ‰€æœ‰å›¾ç‰‡çš„æ•°é‡
                self.indices: è®°è½½ç€æ‰€æœ‰å›¾ç‰‡çš„index
                self.rect=Trueæ—¶self.batch_shapesè®°è½½æ¯ä¸ªbatchçš„shape(åŒä¸€ä¸ªbatchçš„å›¾ç‰‡shapeç›¸åŒ)
        """
        # 1ã€èµ‹å€¼ä¸€äº›åŸºç¡€çš„selfå˜é‡ ç”¨äºåé¢åœ¨__getitem__ä¸­è°ƒç”¨
        self.img_size = img_size    # ç»è¿‡æ•°æ®å¢å¼ºåçš„æ•°æ®å›¾ç‰‡çš„å¤§å°
        self.augment = augment  # æ˜¯å¦å¯åŠ¨æ•°æ®å¢å¼º ä¸€èˆ¬è®­ç»ƒæ—¶æ‰“å¼€ éªŒè¯æ—¶å…³é—­
        self.hyp = hyp  # è¶…å‚åˆ—è¡¨
        # å›¾ç‰‡æŒ‰æƒé‡é‡‡æ ·  Trueå°±å¯ä»¥æ ¹æ®ç±»åˆ«é¢‘ç‡(é¢‘ç‡é«˜çš„æƒé‡å°,åæ­£å¤§)æ¥è¿›è¡Œé‡‡æ ·  é»˜è®¤False: ä¸ä½œç±»åˆ«åŒºåˆ†
        self.image_weights = image_weights
        self.rect = False if image_weights else rect # æ˜¯å¦å¯åŠ¨çŸ©å½¢è®­ç»ƒ ä¸€èˆ¬è®­ç»ƒæ—¶å…³é—­ éªŒè¯æ—¶æ‰“å¼€ å¯ä»¥åŠ é€Ÿ
        self.mosaic = self.augment and not self.rect  # load 4 images at a time into a mosaic (only during training)
        # mosaicå¢å¼ºçš„è¾¹ç•Œå€¼  [-320, -320]
        self.mosaic_border = [-img_size // 2, -img_size // 2]
        self.stride = stride # æœ€å¤§ä¸‹é‡‡æ ·ç‡ 32
        self.path = path  # å›¾ç‰‡è·¯å¾„
        self.albumentations = Albumentations() if augment else None

        # 2ã€å¾—åˆ°pathè·¯å¾„ä¸‹çš„æ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„self.img_filesï¼Œè¿™é‡Œéœ€è¦è‡ªå·±debugä¸€ä¸‹ ä¸ä¼šå¤ªéš¾
        try:
            f = []  # image files
            for p in path if isinstance(path, list) else [path]: # ä¸»è¦ç”¨æ¥å¤„ç†windowä¸linuxçš„åŒºåˆ«
                # è·å–æ•°æ®é›†è·¯å¾„pathï¼ŒåŒ…å«å›¾ç‰‡è·¯å¾„çš„txtæ–‡ä»¶æˆ–è€…åŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„
                # ä½¿ç”¨pathlib.Pathç”Ÿæˆä¸æ“ä½œç³»ç»Ÿæ— å…³çš„è·¯å¾„ï¼Œå› ä¸ºä¸åŒæ“ä½œç³»ç»Ÿè·¯å¾„çš„â€˜/â€™ä¼šæœ‰æ‰€ä¸åŒ
                p = Path(p)  # os-agnostic
                # å¦‚æœè·¯å¾„pathä¸ºåŒ…å«å›¾ç‰‡çš„æ–‡ä»¶å¤¹è·¯å¾„
                if p.is_dir():  # dir
                    # glob.glab: è¿”å›æ‰€æœ‰åŒ¹é…çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨  é€’å½’è·å–pè·¯å¾„ä¸‹æ‰€æœ‰æ–‡ä»¶
                    f += glob.glob(str(p / '**' / '*.*'), recursive=True)
                    # f = list(p.rglob('*.*'))  # pathlib
                # å¦‚æœè·¯å¾„pathä¸ºåŒ…å«å›¾ç‰‡è·¯å¾„çš„txtæ–‡ä»¶
                elif p.is_file():  # file
                    with open(p) as t:
                        t = t.read().strip().splitlines()  # è·å–å›¾ç‰‡è·¯å¾„ï¼Œæ›´æ¢ç›¸å¯¹è·¯å¾„
                        # è·å–æ•°æ®é›†è·¯å¾„çš„ä¸Šçº§çˆ¶ç›®å½•  os.sepä¸ºè·¯å¾„é‡Œçš„åˆ†éš”ç¬¦ï¼ˆä¸åŒè·¯å¾„çš„åˆ†éš”ç¬¦ä¸åŒï¼Œos.sepå¯ä»¥æ ¹æ®ç³»ç»Ÿè‡ªé€‚åº”ï¼‰
                        parent = str(p.parent) + os.sep
                        f += [x.replace('./', parent) if x.startswith('./') else x for x in t]  # local to global path
                        # f += [p.parent / x.lstrip(os.sep) for x in t]  # local to global path (pathlib)
                else:
                    raise Exception(f'{prefix}{p} does not exist')
            # ç ´æŠ˜å·æ›¿æ¢ä¸ºos.sepï¼Œos.path.splitext(x)å°†æ–‡ä»¶åä¸æ‰©å±•ååˆ†å¼€å¹¶è¿”å›ä¸€ä¸ªåˆ—è¡¨
            # ç­›é€‰fä¸­æ‰€æœ‰çš„å›¾ç‰‡æ–‡ä»¶
            self.img_files = sorted(x.replace('/', os.sep) for x in f if x.split('.')[-1].lower() in IMG_FORMATS)
            # self.img_files = sorted([x for x in f if x.suffix[1:].lower() in IMG_FORMATS])  # pathlib
            assert self.img_files, f'{prefix}No images found'
        except Exception as e:
            raise Exception(f'{prefix}Error loading data from {path}: {e}\nSee {HELP_URL}')

        # 3ã€æ ¹æ®imgsè·¯å¾„æ‰¾åˆ°labelsçš„è·¯å¾„self.label_files
        self.label_files = img2label_paths(self.img_files)  # labels

        # 4ã€cache label ä¸‹æ¬¡è¿è¡Œè¿™ä¸ªè„šæœ¬çš„æ—¶å€™ç›´æ¥ä»cacheä¸­å–labelï¼Œè€Œä¸æ˜¯å»æ–‡ä»¶ä¸­å–label é€Ÿåº¦æ›´å¿«ã€‚
        cache_path = (p if p.is_file() else Path(self.label_files[0]).parent).with_suffix('.cache')
        try:
            # å¦‚æœæœ‰cacheæ–‡ä»¶ï¼Œç›´æ¥åŠ è½½  exists=True: æ˜¯å¦å·²ä»cacheæ–‡ä»¶ä¸­è¯»å‡ºäº†nf, nm, ne, nc, nç­‰ä¿¡æ¯
            cache, exists = np.load(cache_path, allow_pickle=True).item(), True  # load dict
            # å¦‚æœå›¾ç‰‡ç‰ˆæœ¬ä¿¡æ¯æˆ–è€…æ–‡ä»¶åˆ—è¡¨çš„hashå€¼å¯¹ä¸ä¸Šå· è¯´æ˜æœ¬åœ°æ•°æ®é›†å›¾ç‰‡å’Œlabelå¯èƒ½å‘ç”Ÿäº†å˜åŒ– å°±é‡æ–°cache labelæ–‡ä»¶
            assert cache['version'] == self.cache_version  # same version
            assert cache['hash'] == get_hash(self.label_files + self.img_files)  # same hash
        except Exception:
            # å¦åˆ™è°ƒç”¨cache_labelsç¼“å­˜æ ‡ç­¾åŠæ ‡ç­¾ç›¸å…³ä¿¡æ¯
            cache, exists = self.cache_labels(cache_path, prefix), False  # cache

        # æ‰“å°cacheçš„ç»“æœ nf nm ne nc n = æ‰¾åˆ°çš„æ ‡ç­¾æ•°é‡ï¼Œæ¼æ‰çš„æ ‡ç­¾æ•°é‡ï¼Œç©ºçš„æ ‡ç­¾æ•°é‡ï¼ŒæŸåçš„æ ‡ç­¾æ•°é‡ï¼Œæ€»çš„æ ‡ç­¾æ•°é‡
        nf, nm, ne, nc, n = cache.pop('results')  # found, missing, empty, corrupt, total
        # å¦‚æœå·²ç»ä»cacheæ–‡ä»¶è¯»å‡ºäº†nf nm ne nc nç­‰ä¿¡æ¯ï¼Œç›´æ¥æ˜¾ç¤ºæ ‡ç­¾ä¿¡æ¯  msgsä¿¡æ¯ç­‰
        if exists:
            d = f"Scanning '{cache_path}' images and labels... {nf} found, {nm} missing, {ne} empty, {nc} corrupt"
            tqdm(None, desc=prefix + d, total=n, initial=n)  # display cache results
            if cache['msgs']:
                LOGGER.info('\n'.join(cache['msgs']))  # display warnings
        # æ•°æ®é›†æ²¡æœ‰æ ‡ç­¾ä¿¡æ¯ å°±å‘å‡ºè­¦å‘Šå¹¶æ˜¾ç¤ºæ ‡ç­¾labelä¸‹è½½åœ°å€help_url
        assert nf > 0 or not augment, f'{prefix}No labels in {cache_path}. Can not train without labels. See {HELP_URL}'

        # 5ã€Read cache  ä»cacheä¸­è¯»å‡ºæœ€æ–°å˜é‡èµ‹ç»™self  æ–¹ä¾¿ç»™forwardä¸­ä½¿ç”¨
        # cacheä¸­çš„é”®å€¼å¯¹æœ€åˆæœ‰: cache[img_file]=[l, shape, segments] cache[hash] cache[results] cache[msg] cache[version]
        # å…ˆä»cacheä¸­å»é™¤cacheæ–‡ä»¶ä¸­å…¶ä»–æ— å…³é”®å€¼å¦‚:'hash', 'version', 'msgs'ç­‰éƒ½åˆ é™¤
        [cache.pop(k) for k in ('hash', 'version', 'msgs')]  # remove items

        # popæ‰resultsã€hashã€versionã€msgsååªå‰©ä¸‹cache[img_file]=[l, shape, segments]
        #   cache.values(): å–cacheä¸­æ‰€æœ‰å€¼ å¯¹åº”æ‰€æœ‰l, shape, segments
        # labels: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  labelså­˜å‚¨çš„labelå°±éƒ½æ˜¯åŸå§‹label(éƒ½æ˜¯æ­£å¸¸çš„çŸ©å½¢label)
        #         å¦åˆ™å°†æ‰€æœ‰å›¾ç‰‡æ­£å¸¸gtçš„labelå­˜å…¥labels ä¸æ­£å¸¸gt(å­˜åœ¨ä¸€ä¸ªå¤šè¾¹å½¢)ç»è¿‡segments2boxesè½¬æ¢ä¸ºæ­£å¸¸çš„çŸ©å½¢label
        # shapes: æ‰€æœ‰å›¾ç‰‡çš„shape
        # self.segments: å¦‚æœæ•°æ®é›†æ‰€æœ‰å›¾ç‰‡ä¸­æ²¡æœ‰ä¸€ä¸ªå¤šè¾¹å½¢label  self.segments=None
        #                å¦åˆ™å­˜å‚¨æ•°æ®é›†ä¸­æ‰€æœ‰å­˜åœ¨å¤šè¾¹å½¢gtçš„å›¾ç‰‡çš„æ‰€æœ‰åŸå§‹label(è‚¯å®šæœ‰å¤šè¾¹å½¢label ä¹Ÿå¯èƒ½æœ‰çŸ©å½¢æ­£å¸¸label æœªçŸ¥æ•°)
        # zip æ˜¯å› ä¸ºcacheä¸­æ‰€æœ‰labelsã€shapesã€segmentsä¿¡æ¯éƒ½æ˜¯æŒ‰æ¯å¼ imgåˆ†å¼€å­˜å‚¨çš„, zipæ˜¯å°†æ‰€æœ‰å›¾ç‰‡å¯¹åº”çš„ä¿¡æ¯å åœ¨ä¸€èµ·
        labels, shapes, self.segments = zip(*cache.values())    # segments: éƒ½æ˜¯[]
        self.labels = list(labels)
        self.shapes = np.array(shapes, dtype=np.float64)    # image shapes to float64
        self.img_files = list(cache.keys())  # æ›´æ–°æ‰€æœ‰å›¾ç‰‡çš„img_filesä¿¡æ¯ update img_files from cache result
        self.label_files = img2label_paths(cache.keys())  # æ›´æ–°æ‰€æœ‰å›¾ç‰‡çš„label_filesä¿¡æ¯(å› ä¸ºimg_filesä¿¡æ¯å¯èƒ½å‘ç”Ÿäº†å˜åŒ–)
        n = len(shapes)  # å½“å‰æ•°æ®é›†å›¾ç‰‡
        bi = np.floor(np.arange(n) / batch_size).astype(int)  # å¾—åˆ°batchåºåˆ—
        nb = bi[-1] + 1  # å¾—åˆ°batchçš„æ•°é‡
        self.batch = bi  # batch index of image
        self.n = n  # number of images
        self.indices = range(n) # æ‰€æœ‰å›¾ç‰‡çš„index

        # Update labels
        include_class = []  # filter labels to include only these classes (optional)
        include_class_array = np.array(include_class).reshape(1, -1)
        for i, (label, segment) in enumerate(zip(self.labels, self.segments)):
            if include_class:
                j = (label[:, 0:1] == include_class_array).any(1)
                self.labels[i] = label[j]
                if segment:
                    self.segments[i] = segment[j]
            if single_cls:  # single-class training, merge all classes into 0
                self.labels[i][:, 0] = 0
                if segment:
                    self.segments[i][:, 0] = 0

        # 6ã€ä¸ºRectangular Trainingä½œå‡†å¤‡ï¼šå³å‡å°‘å¤§å°ä¸åŒå›¾ç‰‡å¤„ç†æ—¶ï¼Œå¯¹äºå¤šä½™çš„é»‘è¾¹åšåˆ°æœ€å°ï¼Œå®ç°é™ä½è®¡ç®—é‡
        # è¿™é‡Œä¸»è¦æ˜¯æ³¨æ„shapesçš„ç”Ÿæˆ è¿™ä¸€æ­¥å¾ˆé‡è¦ å› ä¸ºå¦‚æœé‡‡æ ·çŸ©å½¢è®­ç»ƒé‚£ä¹ˆæ•´ä¸ªbatchçš„å½¢çŠ¶è¦ä¸€æ · å°±è¦è®¡ç®—è¿™ä¸ªç¬¦åˆæ•´ä¸ªbatchçš„shape
        # è€Œä¸”è¿˜è¦å¯¹æ•°æ®é›†æŒ‰ç…§é«˜å®½æ¯”è¿›è¡Œæ’åº è¿™æ ·æ‰èƒ½ä¿è¯åŒä¸€ä¸ªbatchçš„å›¾ç‰‡çš„å½¢çŠ¶å·®ä¸å¤šç›¸åŒ å†é€‰æ‹©ä¸€ä¸ªå…±åŒçš„shapeä»£ä»·ä¹Ÿæ¯”è¾ƒå°
        if self.rect:
            #  æ‰€æœ‰è®­ç»ƒå›¾ç‰‡çš„shape
            s = self.shapes  # wh
            # è®¡ç®—é«˜å®½æ¯”
            ar = s[:, 1] / s[:, 0]  # aspect ratio
            irect = ar.argsort()    # æ ¹æ®é«˜å®½æ¯”æ’åº
            self.img_files = [self.img_files[i] for i in irect] # è·å–æ’åºåçš„img_files
            self.label_files = [self.label_files[i] for i in irect]  # è·å–æ’åºåçš„label_files
            self.labels = [self.labels[i] for i in irect]   # è·å–æ’åºåçš„labels
            self.shapes = s[irect]   # è·å–æ’åºåçš„wh
            ar = ar[irect]   # è·å–æ’åºåçš„wh

            # è®¡ç®—æ¯ä¸ªbatché‡‡ç”¨çš„ç»Ÿä¸€å°ºåº¦ Set training image shapes
            shapes = [[1, 1]] * nb
            for i in range(nb):
                # åŒä¸€ä¸ªbatchçš„å›¾ç‰‡æå–å‡ºæ¥
                ari = ar[bi == i]
                mini, maxi = ari.min(), ari.max()   # è·å–ç¬¬iä¸ªbatchä¸­ï¼Œæœ€å°å’Œæœ€å¤§é«˜å®½æ¯”
                if maxi < 1:
                    # [H,W]å¦‚æœé«˜/å®½å°äº1(w > h)ï¼Œå®½å¤§äºé«˜ï¼ŒçŸ®èƒ–å‹ï¼Œ(img_size*maxi,img_size)ï¼ˆä¿è¯åŸå›¾åƒå°ºåº¦ä¸å˜è¿›è¡Œç¼©æ”¾ï¼‰
                    shapes[i] = [maxi, 1]
                elif mini > 1:
                    # [H,W]å¦‚æœé«˜/å®½å¤§äº1(w < h)ï¼Œå®½å°äºé«˜ï¼Œç˜¦é«˜å‹ï¼Œ(img_size,img_size *ï¼ˆ1/miniï¼‰)ï¼ˆä¿è¯åŸå›¾åƒå°ºåº¦ä¸å˜è¿›è¡Œç¼©æ”¾ï¼‰
                    shapes[i] = [1, 1 / mini]
            # è®¡ç®—æ¯ä¸ªbatchè¾“å…¥ç½‘ç»œçš„shapeå€¼(å‘ä¸Šè®¾ç½®ä¸º32çš„æ•´æ•°å€)
            # è¦æ±‚æ¯ä¸ªbatch_shapesçš„é«˜å®½éƒ½æ˜¯32çš„æ•´æ•°å€ï¼Œæ‰€ä»¥è¦å…ˆé™¤ä»¥32ï¼Œå–æ•´å†ä¹˜ä»¥32ï¼ˆä¸è¿‡img_sizeå¦‚æœæ˜¯32å€æ•°è¿™é‡Œå°±æ²¡å¿…è¦äº†ï¼‰
            self.batch_shapes = np.ceil(np.array(shapes) * img_size / stride + pad).astype(int) * stride

        # 7ã€æ˜¯å¦éœ€è¦cache image ä¸€èˆ¬æ˜¯False å› ä¸ºRAMä¼šä¸è¶³  cache labelè¿˜å¯ä»¥ ä½†æ˜¯cache imageå°±å¤ªå¤§äº† æ‰€ä»¥ä¸€èˆ¬ä¸ç”¨
        # Cache images into memory for faster training (WARNING: large datasets may exceed system RAM)
        self.imgs, self.img_npy = [None] * n, [None] * n
        if cache_images:
            if cache_images == 'disk':
                self.im_cache_dir = Path(Path(self.img_files[0]).parent.as_posix() + '_npy')
                self.img_npy = [self.im_cache_dir / Path(f).with_suffix('.npy').name for f in self.img_files]
                self.im_cache_dir.mkdir(parents=True, exist_ok=True)
            gb = 0  # Gigabytes of cached images
            self.img_hw0, self.img_hw = [None] * n, [None] * n
            results = ThreadPool(NUM_THREADS).imap(self.load_image, range(n))
            pbar = tqdm(enumerate(results), total=n)
            for i, x in pbar:
                if cache_images == 'disk':
                    if not self.img_npy[i].exists():
                        np.save(self.img_npy[i].as_posix(), x[0])
                    gb += self.img_npy[i].stat().st_size
                else:  # 'ram'
                    self.imgs[i], self.img_hw0[i], self.img_hw[i] = x  # im, hw_orig, hw_resized = load_image(self, i)
                    gb += self.imgs[i].nbytes
                pbar.desc = f'{prefix}Caching images ({gb / 1E9:.1f}GB {cache_images})'
            pbar.close()

    def cache_labels(self, path=Path('./labels.cache'), prefix=''):
        """
                ç”¨åœ¨__init__å‡½æ•°ä¸­  cacheæ•°æ®é›†label

                è¿™ä¸ªå‡½æ•°ç”¨äºåŠ è½½æ–‡ä»¶è·¯å¾„ä¸­çš„labelä¿¡æ¯ç”Ÿæˆcacheæ–‡ä»¶ã€‚
                cacheæ–‡ä»¶ä¸­åŒ…æ‹¬çš„ä¿¡æ¯æœ‰ï¼šim_file, l, shape, segments, hash, results, msgs, versionç­‰ï¼Œå…·ä½“çœ‹ä»£ç æ³¨é‡Šã€‚

               åŠ è½½labelä¿¡æ¯ç”Ÿæˆcacheæ–‡ä»¶   Cache dataset labels, check images and read shapes

               :params path: cacheæ–‡ä»¶ä¿å­˜åœ°å€
               :params prefix: æ—¥å¿—å¤´éƒ¨ä¿¡æ¯(å½©æ‰“é«˜äº®éƒ¨åˆ†)
               :return x: cacheä¸­ä¿å­˜çš„å­—å…¸
                      åŒ…æ‹¬çš„ä¿¡æ¯æœ‰: x[im_file] = [l, shape, segments]
                                 ä¸€å¼ å›¾ç‰‡ä¸€ä¸ªlabelç›¸å¯¹åº”çš„ä¿å­˜åˆ°x, æœ€ç»ˆxä¼šä¿å­˜æ‰€æœ‰å›¾ç‰‡çš„ç›¸å¯¹è·¯å¾„ã€gtæ¡†çš„ä¿¡æ¯ã€å½¢çŠ¶shapeã€æ‰€æœ‰çš„å¤šè¾¹å½¢gtä¿¡æ¯
                                     im_file: å½“å‰è¿™å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
                                     l: å½“å‰è¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(ä¸åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, cls+xywh(normalized)]
                                     shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
                                     segments: å½“å‰è¿™å¼ å›¾ç‰‡æ‰€æœ‰gtçš„labelä¿¡æ¯(åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
                                  hash: å½“å‰å›¾ç‰‡å’Œlabelæ–‡ä»¶çš„hashå€¼  1
                                  results: æ‰¾åˆ°çš„labelä¸ªæ•°nf, ä¸¢å¤±labelä¸ªæ•°nm, ç©ºlabelä¸ªæ•°ne, ç ´æŸlabelä¸ªæ•°nc, æ€»img/labelä¸ªæ•°len(self.img_files)
                                  msgs: æ‰€æœ‰æ•°æ®é›†çš„msgsä¿¡æ¯
                                  version: å½“å‰cache version
               """
        x = {}  # åˆå§‹åŒ–æœ€ç»ˆcacheä¸­ä¿å­˜çš„å­—å…¸dict
        # åˆå§‹åŒ–number missing, found, empty, corrupt, messages
        # åˆå§‹åŒ–æ•´ä¸ªæ•°æ®é›†: æ¼æ‰çš„æ ‡ç­¾(label)æ€»æ•°é‡, æ‰¾åˆ°çš„æ ‡ç­¾(label)æ€»æ•°é‡, ç©ºçš„æ ‡ç­¾(label)æ€»æ•°é‡, é”™è¯¯æ ‡ç­¾(label)æ€»æ•°é‡, æ‰€æœ‰é”™è¯¯ä¿¡æ¯
        nm, nf, ne, nc, msgs = 0, 0, 0, 0, []  # number missing, found, empty, corrupt, messages
        desc = f"{prefix}Scanning '{path.parent / path.stem}' images and labels..." # æ—¥å¿—
        # å¤šè¿›ç¨‹è°ƒç”¨verify_image_labelå‡½æ•°
        with Pool(NUM_THREADS) as pool:
            # å®šä¹‰pbarè¿›åº¦æ¡
            # pool.imap_unordered: å¯¹å¤§é‡æ•°æ®éå†å¤šè¿›ç¨‹è®¡ç®— è¿”å›ä¸€ä¸ªè¿­ä»£å™¨
            # æŠŠself.img_files, self.label_files, repeat(prefix) listä¸­çš„å€¼ä½œä¸ºå‚æ•°ä¾æ¬¡é€å…¥(ä¸€æ¬¡é€ä¸€ä¸ª)verify_image_labelå‡½æ•°
            pbar = tqdm(pool.imap(verify_image_label, zip(self.img_files, self.label_files, repeat(prefix))),
                        desc=desc, total=len(self.img_files))
            # im_file: å½“å‰è¿™å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
            # l: [gt_num, cls+xywh(normalized)]
            #    å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ lå°±å­˜å‚¨åŸlabel(å…¨éƒ¨æ˜¯æ­£å¸¸çŸ©å½¢æ ‡ç­¾)
            #    å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾  lå°±å­˜å‚¨ç»è¿‡segments2boxeså¤„ç†å¥½çš„æ ‡ç­¾(æ­£å¸¸çŸ©å½¢æ ‡ç­¾ä¸å¤„ç† å¤šè¾¹å½¢æ ‡ç­¾è½¬åŒ–ä¸ºçŸ©å½¢æ ‡ç­¾)
            # shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
            # segments: å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å­˜å‚¨None
            #           å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å°±æŠŠè¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰labelå­˜å‚¨åˆ°segmentsä¸­(è‹¥å¹²ä¸ªæ­£å¸¸gt è‹¥å¹²ä¸ªå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
            # nm_f(nm): number missing å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦ä¸¢å¤±         ä¸¢å¤±=1    å­˜åœ¨=0
            # nf_f(nf): number found å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦å­˜åœ¨           å­˜åœ¨=1    ä¸¢å¤±=0
            # ne_f(ne): number empty å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦æ˜¯ç©ºçš„         ç©ºçš„=1    æ²¡ç©º=0
            # nc_f(nc): number corrupt å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ–‡ä»¶æ˜¯å¦æ˜¯ç ´æŸçš„  ç ´æŸçš„=1  æ²¡ç ´æŸ=0
            # msg: è¿”å›çš„msgä¿¡æ¯  labelæ–‡ä»¶å®Œå¥½=â€˜â€™  labelæ–‡ä»¶ç ´æŸ=warningä¿¡æ¯
            for im_file, lb, shape, segments, nm_f, nf_f, ne_f, nc_f, msg in pbar:
                nm += nm_f  # ç´¯åŠ æ€»number missing label
                nf += nf_f  # ç´¯åŠ æ€»number found label
                ne += ne_f  # ç´¯åŠ æ€»number empty label
                nc += nc_f  # ç´¯åŠ æ€»number corrupt label
                if im_file:
                    x[im_file] = [lb, shape, segments]  # ä¿¡æ¯å­˜å…¥å­—å…¸ key=im_file  value=[l, shape, segments]
                if msg:
                    msgs.append(msg)    # å°†msgåŠ å…¥æ€»msg
                pbar.desc = f"{desc}{nf} found, {nm} missing, {ne} empty, {nc} corrupt"

        pbar.close()    # å…³é—­è¿›åº¦æ¡

        # æ—¥å¿—æ‰“å°æ‰€æœ‰msgä¿¡æ¯
        if msgs:
            LOGGER.info('\n'.join(msgs))
        # ä¸€å¼ labeléƒ½æ²¡æ‰¾åˆ° æ—¥å¿—æ‰“å°help_urlä¸‹è½½åœ°å€
        if nf == 0:
            LOGGER.warning(f'{prefix}WARNING: No labels found in {path}. See {HELP_URL}')
        x['hash'] = get_hash(self.label_files + self.img_files) # å°†å½“å‰å›¾ç‰‡å’Œlabelæ–‡ä»¶çš„hashå€¼å­˜å…¥æœ€ç»ˆå­—å…¸dist
        x['results'] = nf, nm, ne, nc, len(self.img_files)  # å°†nf, nm, ne, nc, len(self.img_files)å­˜å…¥æœ€ç»ˆå­—å…¸dist
        x['msgs'] = msgs  # å°†æ‰€æœ‰æ•°æ®é›†çš„msgsä¿¡æ¯å­˜å…¥æœ€ç»ˆå­—å…¸dist
        x['version'] = self.cache_version  # å°†å½“å‰cache versionå­˜å…¥æœ€ç»ˆå­—å…¸dist
        try:
            np.save(path, x)  # save cache for next time
            path.with_suffix('.cache.npy').rename(path)  # remove .npy suffix
            LOGGER.info(f'{prefix}New cache created: {path}')
        except Exception as e:
            LOGGER.warning(f'{prefix}WARNING: Cache directory {path.parent} is not writeable: {e}')  # not writeable
        return x

    def __len__(self):
        # è¿™ä¸ªå‡½æ•°æ˜¯æ±‚æ•°æ®é›†å›¾ç‰‡çš„æ•°é‡ã€‚
        return len(self.img_files)

    # def __iter__(self):
    #     self.count = -1
    #     print('ran dataset iter')
    #     #self.shuffled_vector = np.random.permutation(self.nF) if self.augment else np.arange(self.nF)
    #     return self

    def __getitem__(self, index):
        """
               è¿™éƒ¨åˆ†æ˜¯æ•°æ®å¢å¼ºå‡½æ•°ï¼Œä¸€èˆ¬ä¸€æ¬¡æ€§æ‰§è¡Œbatch_sizeæ¬¡ã€‚
               è®­ç»ƒ æ•°æ®å¢å¼º: mosaic(random_perspective) + hsv + ä¸Šä¸‹å·¦å³ç¿»è½¬
               æµ‹è¯• æ•°æ®å¢å¼º: letterbox
               :return torch.from_numpy(img): è¿™ä¸ªindexçš„å›¾ç‰‡æ•°æ®(å¢å¼ºå) [3, 640, 640]
               :return labels_out: è¿™ä¸ªindexå›¾ç‰‡çš„gt label [6, 6] = [gt_num, 0+class+xywh(normalized)]
               :return self.img_files[index]: è¿™ä¸ªindexå›¾ç‰‡çš„è·¯å¾„åœ°å€
               :return shapes: è¿™ä¸ªbatchçš„å›¾ç‰‡çš„shapes æµ‹è¯•æ—¶(çŸ©å½¢è®­ç»ƒ)æ‰æœ‰  éªŒè¯æ—¶ä¸ºNone   for COCO mAP rescaling
               """
        # è¿™é‡Œå¯ä»¥é€šè¿‡ä¸‰ç§å½¢å¼è·å–è¦è¿›è¡Œæ•°æ®å¢å¼ºçš„å›¾ç‰‡index  linear, shuffled, or image_weights
        index = self.indices[index]  # linear, shuffled, or image_weights

        hyp = self.hyp  # è¶…å‚ åŒ…å«ä¼—å¤šæ•°æ®å¢å¼ºè¶…å‚
        mosaic = self.mosaic and random.random() < hyp['mosaic']    # æ˜¯å¦ä½¿ç”¨é©¬èµ›å…‹å¤„ç†
        # mosaicå¢å¼º å¯¹å›¾åƒè¿›è¡Œ4å¼ å›¾æ‹¼æ¥è®­ç»ƒ  ä¸€èˆ¬è®­ç»ƒæ—¶è¿è¡Œ
        # mosaic + MixUp
        if mosaic:
            # Load mosaic
            img, labels = self.load_mosaic(index)   # å°†å››å¼ å›¾ç‰‡æ‹¼æ¥åœ¨ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­
            # img, labels = load_mosaic9(self, index)
            shapes = None

            # MixUp augmentation
            # mixupæ•°æ®å¢å¼º
            if random.random() < hyp['mixup']: # hyp['mixup']=0 é»˜è®¤ä¸º0åˆ™å…³é—­ é»˜è®¤ä¸º1åˆ™100%æ‰“å¼€
                # *load_mosaic(self, random.randint(0, self.n - 1)) éšæœºä»æ•°æ®é›†ä¸­ä»»é€‰ä¸€å¼ å›¾ç‰‡å’Œæœ¬å¼ å›¾ç‰‡è¿›è¡Œmixupæ•°æ®å¢å¼º
                # img:   ä¸¤å¼ å›¾ç‰‡èåˆä¹‹åçš„å›¾ç‰‡ numpy (640, 640, 3)
                # labels: ä¸¤å¼ å›¾ç‰‡èåˆä¹‹åçš„æ ‡ç­¾label [M+N, cls+x1y1x2y2]
                img, labels = mixup(img, labels, *self.load_mosaic(random.randint(0, self.n - 1)))
                # æµ‹è¯•ä»£ç  æµ‹è¯•MixUpæ•ˆæœ
                # cv2.imshow("MixUp", img)
                # cv2.waitKey(0)
                # cv2.destroyAllWindows()
                # print(img.shape)   # (640, 640, 3)

                # å¦åˆ™: è½½å…¥å›¾ç‰‡ + Letterbox  (val)
        else:
            # Load image
            # è½½å…¥å›¾ç‰‡  è½½å…¥å›¾ç‰‡åè¿˜ä¼šè¿›è¡Œä¸€æ¬¡resize  å°†å½“å‰å›¾ç‰‡çš„æœ€é•¿è¾¹ç¼©æ”¾åˆ°æŒ‡å®šçš„å¤§å°(512), è¾ƒå°è¾¹åŒæ¯”ä¾‹ç¼©æ”¾
            # load image img=(343, 512, 3)=(h, w, c)  (h0, w0)=(335, 500)  numpy  index=4
            # img: resizeåçš„å›¾ç‰‡   (h0, w0): åŸå§‹å›¾ç‰‡çš„hw  (h, w): resizeåçš„å›¾ç‰‡çš„hw
            # è¿™ä¸€æ­¥æ˜¯å°†(335, 500, 3) resize-> (343, 512, 3)
            img, (h0, w0), (h, w) = self.load_image(index)

            # æµ‹è¯•ä»£ç  æµ‹è¯•load_imageæ•ˆæœ
            # cv2.imshow("load_image", img)
            # cv2.waitKey(0)
            # cv2.destroyAllWindows()
            # print(img.shape)   # (640, 640, 3)

            # Letterbox
            # letterboxä¹‹å‰ç¡®å®šè¿™å¼ å½“å‰å›¾ç‰‡letterboxä¹‹åçš„shape  å¦‚æœä¸ç”¨self.rectçŸ©å½¢è®­ç»ƒshapeå°±æ˜¯self.img_size
            # å¦‚æœä½¿ç”¨self.rectçŸ©å½¢è®­ç»ƒshapeå°±æ˜¯å½“å‰batchçš„shape å› ä¸ºçŸ©å½¢è®­ç»ƒçš„è¯æˆ‘ä»¬æ•´ä¸ªbatchçš„shapeå¿…é¡»ç»Ÿä¸€(åœ¨__init__å‡½æ•°ç¬¬6èŠ‚å†…å®¹)
            shape = self.batch_shapes[self.batch[index]] if self.rect else self.img_size  # final letterboxed shape
            # letterbox è¿™ä¸€æ­¥å°†ç¬¬ä¸€æ­¥ç¼©æ”¾å¾—åˆ°çš„å›¾ç‰‡å†ç¼©æ”¾åˆ°å½“å‰batchæ‰€éœ€è¦çš„å°ºåº¦ (343, 512, 3) pad-> (384, 512, 3)
            # (çŸ©å½¢æ¨ç†éœ€è¦ä¸€ä¸ªbatchçš„æ‰€æœ‰å›¾ç‰‡çš„shapeå¿…é¡»ç›¸åŒï¼Œè€Œè¿™ä¸ªshapeåœ¨initå‡½æ•°ä¸­ä¿æŒåœ¨self.batch_shapesä¸­)
            # è¿™é‡Œæ²¡æœ‰ç¼©æ”¾æ“ä½œï¼Œæ‰€ä»¥è¿™é‡Œçš„ratioæ°¸è¿œéƒ½æ˜¯(1.0, 1.0)  pad=(0.0, 20.5)
            img, ratio, pad = letterbox(img, shape, auto=False, scaleup=self.augment)
            shapes = (h0, w0), ((h / h0, w / w0), pad)  # for COCO mAP rescaling

            # å›¾ç‰‡letterboxä¹‹ålabelçš„åæ ‡ä¹Ÿè¦ç›¸åº”å˜åŒ–  æ ¹æ®padè°ƒæ•´labelåæ ‡ å¹¶å°†å½’ä¸€åŒ–çš„xywh -> æœªå½’ä¸€åŒ–çš„xyxy
            labels = self.labels[index].copy()
            if labels.size:  # normalized xywh to pixel xyxy format
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], ratio[0] * w, ratio[1] * h, padw=pad[0], padh=pad[1])

            # æµ‹è¯•ä»£ç  æµ‹è¯•letterboxæ•ˆæœ
            # cv2.imshow("letterbox", img)
            # cv2.waitKey(0)
            # cv2.destroyAllWindows()
            # print(img.shape)   # (640, 640, 3)

            if self.augment:
                # ä¸åšmosaicçš„è¯å°±è¦åšrandom_perspectiveå¢å¼º å› ä¸ºmosaicå‡½æ•°å†…éƒ¨æ‰§è¡Œäº†random_perspectiveå¢å¼º
                # random_perspectiveå¢å¼º: éšæœºå¯¹å›¾ç‰‡è¿›è¡Œæ—‹è½¬ï¼Œå¹³ç§»ï¼Œç¼©æ”¾ï¼Œè£å‰ªï¼Œé€è§†å˜æ¢
                img, labels = random_perspective(img, labels,
                                                 degrees=hyp['degrees'],
                                                 translate=hyp['translate'],
                                                 scale=hyp['scale'],
                                                 shear=hyp['shear'],
                                                 perspective=hyp['perspective'])

        nl = len(labels)  # number of labels
        if nl:
            labels[:, 1:5] = xyxy2xywhn(labels[:, 1:5], w=img.shape[1], h=img.shape[0], clip=True, eps=1E-3)

        if self.augment:
            # Albumentations
            img, labels = self.albumentations(img, labels)
            nl = len(labels)  # update after albumentations

            # è‰²åŸŸç©ºé—´å¢å¼ºAugment colorspaceï¼šHè‰²è°ƒã€Sé¥±å’Œåº¦ã€Väº®åº¦
            # é€šè¿‡ä¸€äº›éšæœºå€¼æ”¹å˜hsvï¼Œå®ç°æ•°æ®å¢å¼º
            augment_hsv(img, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v'])

            # éšæœºä¸Šä¸‹ç¿»è½¬ flip up-down
            if random.random() < hyp['flipud']:
                img = np.flipud(img)
                if nl:
                    labels[:, 2] = 1 - labels[:, 2]

            # éšæœºå·¦å³ç¿»è½¬ flip left-right
            if random.random() < hyp['fliplr']:
                img = np.fliplr(img)
                if nl:
                    labels[:, 1] = 1 - labels[:, 1]

            # Cutouts
            # labels = cutout(img, labels, p=0.5)
            # nl = len(labels)  # update after cutout

        # 6ä¸ªå€¼çš„tensor åˆå§‹åŒ–æ ‡ç­¾æ¡†å¯¹åº”çš„å›¾ç‰‡åºå·, é…åˆä¸‹é¢çš„collate_fnä½¿ç”¨
        labels_out = torch.zeros((nl, 6))
        if nl:
            labels_out[:, 1:] = torch.from_numpy(labels)

        # Convert
        img = img.transpose((2, 0, 1))[::-1]  # HWC to CHW, BGR to RGB
        img = np.ascontiguousarray(img)

        return torch.from_numpy(img), labels_out, self.img_files[index], shapes

    def load_image(self, i):
        """
            è¢«LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•°å’Œload_mosaicæ¨¡å—ä¸­è½½å…¥å¯¹åº”indexçš„å›¾ç‰‡æ—¶è°ƒç”¨

            è¿™ä¸ªå‡½æ•°æ˜¯æ ¹æ®å›¾ç‰‡indexï¼Œä»selfæˆ–è€…ä»å¯¹åº”å›¾ç‰‡è·¯å¾„ä¸­è½½å…¥å¯¹åº”indexçš„å›¾ç‰‡ å¹¶å°†åŸå›¾ä¸­hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•ã€‚
        """

        """
            loads 1 image from dataset, returns img, original hw, resized hw
            
            :params self: ä¸€èˆ¬æ˜¯å¯¼å…¥LoadImagesAndLabelsä¸­çš„self
            :param i: å½“å‰å›¾ç‰‡çš„index
            :return: img: resizeåçš„å›¾ç‰‡
                    (h0, w0): hw_original  åŸå›¾çš„hw
                    img.shape[:2]: hw_resized resizeåçš„å›¾ç‰‡hw(hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•)
            """

        # æŒ‰indexä»self.imgsä¸­è½½å…¥å½“å‰å›¾ç‰‡, ä½†æ˜¯ç”±äºç¼“å­˜çš„å†…å®¹ä¸€èˆ¬ä¼šä¸å¤Ÿ, æ‰€ä»¥æˆ‘ä»¬ä¸€èˆ¬ä¸ä¼šç”¨self.imgs(cache)ä¿å­˜æ‰€æœ‰çš„å›¾ç‰‡
        im = self.imgs[i]
        # å›¾ç‰‡æ˜¯ç©ºçš„è¯, å°±ä»å¯¹åº”æ–‡ä»¶è·¯å¾„è¯»å‡ºè¿™å¼ å›¾ç‰‡
        if im is None:  # not cached ä¸€èˆ¬éƒ½ä¸ä¼šä½¿ç”¨cacheç¼“å­˜åˆ°self.imgsä¸­
            npy = self.img_npy[i]
            if npy and npy.exists():  # load npy
                im = np.load(npy)
            else:  # read image
                f = self.img_files[i]
                im = cv2.imread(f)  # BGR
                assert im is not None, f'Image Not Found {f}'

            h0, w0 = im.shape[:2]  # orig hw
            # img_size è®¾ç½®çš„æ˜¯é¢„å¤„ç†åè¾“å‡ºçš„å›¾ç‰‡å°ºå¯¸   r=ç¼©æ”¾æ¯”ä¾‹
            r = self.img_size / max(h0, w0)  # ratio
            if r != 1:  # if sizes are not equal
                # cv2.INTER_AREA: åŸºäºåŒºåŸŸåƒç´ å…³ç³»çš„ä¸€ç§é‡é‡‡æ ·æˆ–è€…æ’å€¼æ–¹å¼.è¯¥æ–¹æ³•æ˜¯å›¾åƒæŠ½å–çš„é¦–é€‰æ–¹æ³•, å®ƒå¯ä»¥äº§ç”Ÿæ›´å°‘çš„æ³¢çº¹
                # cv2.INTER_LINEAR: åŒçº¿æ€§æ’å€¼,é»˜è®¤æƒ…å†µä¸‹ä½¿ç”¨è¯¥æ–¹å¼è¿›è¡Œæ’å€¼   æ ¹æ®ratioé€‰æ‹©ä¸åŒçš„æ’å€¼æ–¹å¼
                # å°†åŸå›¾ä¸­hwä¸­è¾ƒå¤§è€…æ‰©å±•åˆ°self.img_size, è¾ƒå°è€…åŒæ¯”ä¾‹æ‰©å±•
                im = cv2.resize(im,
                                (int(w0 * r), int(h0 * r)),
                                interpolation=cv2.INTER_LINEAR if (self.augment or r > 1) else cv2.INTER_AREA)
            return im, (h0, w0), im.shape[:2]  # im, hw_original, hw_resized
        else:
            return self.imgs[i], self.img_hw0[i], self.img_hw[i]  # im, hw_original, hw_resized

    def load_mosaic(self, index):

        """
            è¿™ä¸ªæ¨¡å—å°±æ˜¯å¾ˆæœ‰åçš„mosaicå¢å¼ºæ¨¡å—ï¼Œå‡ ä¹è®­ç»ƒçš„æ—¶å€™éƒ½ä¼šç”¨å®ƒï¼Œå¯ä»¥æ˜¾è‘—çš„æé«˜å°æ ·æœ¬çš„mAPã€‚
            ä»£ç æ˜¯æ•°æ®å¢å¼ºé‡Œé¢æœ€éš¾çš„, ä¹Ÿæ˜¯æœ€æœ‰ä»·å€¼çš„ï¼Œmosaicæ˜¯éå¸¸éå¸¸æœ‰ç”¨çš„æ•°æ®å¢å¼ºtrick, ä¸€å®šè¦ç†Ÿç»ƒæŒæ¡ã€‚
        """

        """
            ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•° è¿›è¡Œmosaicæ•°æ®å¢å¼º
            å°†å››å¼ å›¾ç‰‡æ‹¼æ¥åœ¨ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­  loads images in a 4-mosaic
            :param index: éœ€è¦è·å–çš„å›¾åƒç´¢å¼•
            :return: img4: mosaicå’Œéšæœºé€è§†å˜æ¢åçš„ä¸€å¼ å›¾ç‰‡  numpy(640, 640, 3)
                     labels4: img4å¯¹åº”çš„target  [M, cls+x1y1x2y2]
        """
        # labels4: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ4å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(ä¸åŒ…å«segmentså¤šè¾¹å½¢)
        # segments4: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ4å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢)
        labels4, segments4 = [], []
        s = self.img_size # ä¸€èˆ¬çš„å›¾ç‰‡å¤§å°
        # éšæœºåˆå§‹åŒ–æ‹¼æ¥å›¾åƒçš„ä¸­å¿ƒç‚¹åæ ‡  [0, s*2]ä¹‹é—´éšæœºå–2ä¸ªæ•°ä½œä¸ºæ‹¼æ¥å›¾åƒçš„ä¸­å¿ƒåæ ‡
        yc, xc = (int(random.uniform(-x, 2 * s + x)) for x in self.mosaic_border)  # mosaic center x, y
        # ä»datasetä¸­éšæœºå¯»æ‰¾é¢å¤–çš„ä¸‰å¼ å›¾åƒè¿›è¡Œæ‹¼æ¥ [14, 26, 2, 16] å†éšæœºé€‰ä¸‰å¼ å›¾ç‰‡çš„index
        indices = [index] + random.choices(self.indices, k=3)  # 3 additional image indices
        random.shuffle(indices)
        # éå†å››å¼ å›¾åƒè¿›è¡Œæ‹¼æ¥ 4å¼ ä¸åŒå¤§å°çš„å›¾åƒ => 1å¼ [1472, 1472, 3]çš„å›¾åƒ
        for i, index in enumerate(indices):
            # load image   æ¯æ¬¡æ‹¿ä¸€å¼ å›¾ç‰‡ å¹¶å°†è¿™å¼ å›¾ç‰‡resizeåˆ°self.size(h,w)
            img, _, (h, w) = self.load_image(index)

            # place img in img4
            if i == 0:  # top left  åŸå›¾[375, 500, 3] load_image->[552, 736, 3]   hwc
                # åˆ›å»ºé©¬èµ›å…‹å›¾åƒ [1472, 1472, 3]=[h, w, c]
                img4 = np.full((s * 2, s * 2, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
                # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)   w=736  h = 552  é©¬èµ›å…‹å›¾åƒï¼š(x1a,y1a)å·¦ä¸Šè§’ (x2a,y2a)å³ä¸‹è§’
                x1a, y1a, x2a, y2a = max(xc - w, 0), max(yc - h, 0), xc, yc  # xmin, ymin, xmax, ymax (large image)
                # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬ä¸€å¼ å›¾åƒçš„å³ä¸‹è§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)  å›¾åƒï¼š(x1b,y1b)å·¦ä¸Šè§’ (x2b,y2b)å³ä¸‹è§’
                x1b, y1b, x2b, y2b = w - (x2a - x1a), h - (y2a - y1a), w, h  # xmin, ymin, xmax, ymax (small image)
            elif i == 1:  # top right
                # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)
                x1a, y1a, x2a, y2a = xc, max(yc - h, 0), min(xc + w, s * 2), yc
                # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬äºŒå¼ å›¾åƒçš„å·¦ä¸‹è§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)
                x1b, y1b, x2b, y2b = 0, h - (y2a - y1a), min(w, x2a - x1a), h
            elif i == 2:  # bottom left
                # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)
                x1a, y1a, x2a, y2a = max(xc - w, 0), yc, xc, min(s * 2, yc + h)
                # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬ä¸‰å¼ å›¾åƒçš„å³ä¸Šè§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)
                x1b, y1b, x2b, y2b = w - (x2a - x1a), 0, w, min(y2a - y1a, h)
            elif i == 3:  # bottom right
                # è®¡ç®—é©¬èµ›å…‹å›¾åƒä¸­çš„åæ ‡ä¿¡æ¯(å°†å›¾åƒå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­)
                x1a, y1a, x2a, y2a = xc, yc, min(xc + w, s * 2), min(s * 2, yc + h)
                # è®¡ç®—æˆªå–çš„å›¾åƒåŒºåŸŸä¿¡æ¯(ä»¥xc,ycä¸ºç¬¬å››å¼ å›¾åƒçš„å·¦ä¸Šè§’åæ ‡å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒä¸­ï¼Œä¸¢å¼ƒè¶Šç•Œçš„åŒºåŸŸ)
                x1b, y1b, x2b, y2b = 0, 0, min(w, x2a - x1a), min(y2a - y1a, h)

            # å°†æˆªå–çš„å›¾åƒåŒºåŸŸå¡«å……åˆ°é©¬èµ›å…‹å›¾åƒçš„ç›¸åº”ä½ç½®   img4[h, w, c]
            # å°†å›¾åƒimgçš„ã€(x1b,y1b)å·¦ä¸Šè§’ (x2b,y2b)å³ä¸‹è§’ã€‘åŒºåŸŸæˆªå–å‡ºæ¥å¡«å……åˆ°é©¬èµ›å…‹å›¾åƒçš„ã€(x1a,y1a)å·¦ä¸Šè§’ (x2a,y2a)å³ä¸‹è§’ã€‘åŒºåŸŸ
            img4[y1a:y2a, x1a:x2a] = img[y1b:y2b, x1b:x2b]  # img4[ymin:ymax, xmin:xmax]
            # è®¡ç®—pad(å½“å‰å›¾åƒè¾¹ç•Œä¸é©¬èµ›å…‹è¾¹ç•Œçš„è·ç¦»ï¼Œè¶Šç•Œçš„æƒ…å†µpadw/padhä¸ºè´Ÿå€¼)  ç”¨äºåé¢çš„labelæ˜ å°„
            padw = x1a - x1b    # å½“å‰å›¾åƒä¸é©¬èµ›å…‹å›¾åƒåœ¨wç»´åº¦ä¸Šç›¸å·®å¤šå°‘
            padh = y1a - y1b    # å½“å‰å›¾åƒä¸é©¬èµ›å…‹å›¾åƒåœ¨hç»´åº¦ä¸Šç›¸å·®å¤šå°‘

            # labels: è·å–å¯¹åº”æ‹¼æ¥å›¾åƒçš„æ‰€æœ‰æ­£å¸¸labelä¿¡æ¯(å¦‚æœæœ‰segmentså¤šè¾¹å½¢ä¼šè¢«è½¬åŒ–ä¸ºçŸ©å½¢label)
            # segments: è·å–å¯¹åº”æ‹¼æ¥å›¾åƒçš„æ‰€æœ‰ä¸æ­£å¸¸labelä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢ä¹ŸåŒ…å«æ­£å¸¸gt)
            # åœ¨æ–°å›¾ä¸­æ›´æ–°åæ ‡å€¼
            labels, segments = self.labels[index].copy(), self.segments[index].copy()
            if labels.size:
                # normalized xywh normalized to pixel xyxy format
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padw, padh)  # normalized xywh to pixel xyxy format
                segments = [xyn2xy(x, w, h, padw, padh) for x in segments]
            labels4.append(labels) # æ›´æ–°labels4
            segments4.extend(segments) # æ›´æ–°segments4

        # Concat/clip labels4 æŠŠlabels4ï¼ˆ[(2, 5), (1, 5), (3, 5), (1, 5)] => (7, 5)ï¼‰å‹ç¼©åˆ°ä¸€èµ·
        labels4 = np.concatenate(labels4, 0)
        # é˜²æ­¢è¶Šç•Œ  label[:, 1:]ä¸­çš„æ‰€æœ‰å…ƒç´ çš„å€¼ï¼ˆä½ç½®ä¿¡æ¯ï¼‰å¿…é¡»åœ¨[0, 2*s]ä¹‹é—´,å°äº0å°±ä»¤å…¶ç­‰äº0,å¤§äº2*så°±ç­‰äº2*s   out: è¿”å›
        for x in (labels4[:, 1:], *segments4):
            np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
        # img4, labels4 = replicate(img4, labels4)  # replicate

        # æµ‹è¯•ä»£ç   æµ‹è¯•å‰é¢çš„mosaicæ•ˆæœ
        # cv2.imshow("mosaic", img4)
        # cv2.waitKey(0)
        # cv2.destroyAllWindows()
        # print(img4.shape)   # (1280, 1280, 3)

        # éšæœºåç§»æ ‡ç­¾ä¸­å¿ƒï¼Œç”Ÿæˆæ–°çš„æ ‡ç­¾ä¸åŸæ ‡ç­¾ç»“åˆ replicate
        # img4, labels4 = replicate(img4, labels4)
        #
        # # æµ‹è¯•ä»£ç   æµ‹è¯•replicateæ•ˆæœ
        # cv2.imshow("replicate", img4)
        # cv2.waitKey(0)
        # cv2.destroyAllWindows()
        # print(img4.shape)   # (1280, 1280, 3)

        # Augment
        # random_perspective Augment  éšæœºé€è§†å˜æ¢ [1280, 1280, 3] => [640, 640, 3]
        # å¯¹mosaicæ•´åˆåçš„å›¾ç‰‡è¿›è¡Œéšæœºæ—‹è½¬ã€å¹³ç§»ã€ç¼©æ”¾ã€è£å‰ªï¼Œé€è§†å˜æ¢ï¼Œå¹¶resizeä¸ºè¾“å…¥å¤§å°img_size
        img4, labels4, segments4 = copy_paste(img4, labels4, segments4, p=self.hyp['copy_paste'])
        img4, labels4 = random_perspective(img4, labels4, segments4,
                                           degrees=self.hyp['degrees'], # æ—‹è½¬
                                           translate=self.hyp['translate'], # å¹³ç§»
                                           scale=self.hyp['scale'], # ç¼©æ”¾
                                           shear=self.hyp['shear'], # é”™åˆ‡/éå‚ç›´æŠ•å½±
                                           perspective=self.hyp['perspective'], # é€è§†å˜æ¢
                                           border=self.mosaic_border)  # border to remove
        # æµ‹è¯•ä»£ç  æµ‹è¯•mosaic + random_perspectiveéšæœºä»¿å°„å˜æ¢æ•ˆæœ
        # cv2.imshow("random_perspective", img4)
        # cv2.waitKey(0)
        # cv2.destroyAllWindows()
        # print(img4.shape)   # (640, 640, 3)

        return img4, labels4

    def load_mosaic9(self, index):
        """
            ä½œè€…çš„å®éªŒæ¨¡å—ï¼Œå°†ä¹å¼ å›¾ç‰‡æ‹¼æ¥åœ¨ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­ã€‚
        """
        """
            ç”¨åœ¨LoadImagesAndLabelsæ¨¡å—çš„__getitem__å‡½æ•° æ›¿æ¢mosaicæ•°æ®å¢å¼º
            å°†ä¹å¼ å›¾ç‰‡æ‹¼æ¥åœ¨ä¸€å¼ é©¬èµ›å…‹å›¾åƒä¸­  loads images in a 9-mosaic
            :param self:
            :param index: éœ€è¦è·å–çš„å›¾åƒç´¢å¼•
            :return: img9: mosaicå’Œä»¿å°„å¢å¼ºåçš„ä¸€å¼ å›¾ç‰‡
                     labels9: img9å¯¹åº”çš„target
            """
        # labels9: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ9å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(ä¸åŒ…å«segmentså¤šè¾¹å½¢)
        # segments9: ç”¨äºå­˜æ”¾æ‹¼æ¥å›¾åƒï¼ˆ9å¼ å›¾æ‹¼æˆä¸€å¼ ï¼‰çš„labelä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢)
        labels9, segments9 = [], []
        s = self.img_size # ä¸€èˆ¬çš„å›¾ç‰‡å¤§å°(ä¹Ÿæ˜¯æœ€ç»ˆè¾“å‡ºçš„å›¾ç‰‡å¤§å°)
        # ä»datasetä¸­éšæœºå¯»æ‰¾é¢å¤–çš„ä¸‰å¼ å›¾åƒè¿›è¡Œæ‹¼æ¥ [14, 26, 2, 16] å†éšæœºé€‰ä¸‰å¼ å›¾ç‰‡çš„index
        indices = [index] + random.choices(self.indices, k=8)  # 8 additional image indices
        random.shuffle(indices)
        hp, wp = -1, -1  # height, width previous
        for i, index in enumerate(indices):
            # Load image  æ¯æ¬¡æ‹¿ä¸€å¼ å›¾ç‰‡ å¹¶å°†è¿™å¼ å›¾ç‰‡resizeåˆ°self.size(h,w)
            img, _, (h, w) = self.load_image(index)

            # è¿™é‡Œå’Œä¸Šé¢load_mosaicå‡½æ•°çš„æ“ä½œç±»ä¼¼ å°±æ˜¯å°†å–å‡ºçš„imgå›¾ç‰‡åµŒåˆ°img9ä¸­(ä¸æ˜¯çœŸçš„åµŒå…¥ è€Œæ˜¯æ‰¾åˆ°å¯¹åº”çš„ä½ç½®)
            # place img in img9
            if i == 0:  # center
                img9 = np.full((s * 3, s * 3, img.shape[2]), 114, dtype=np.uint8)  # base image with 4 tiles
                h0, w0 = h, w
                c = s, s, s + w, s + h  # xmin, ymin, xmax, ymax (base) coordinates
            elif i == 1:  # top
                c = s, s - h, s + w, s
            elif i == 2:  # top right
                c = s + wp, s - h, s + wp + w, s
            elif i == 3:  # right
                c = s + w0, s, s + w0 + w, s + h
            elif i == 4:  # bottom right
                c = s + w0, s + hp, s + w0 + w, s + hp + h
            elif i == 5:  # bottom
                c = s + w0 - w, s + h0, s + w0, s + h0 + h
            elif i == 6:  # bottom left
                c = s + w0 - wp - w, s + h0, s + w0 - wp, s + h0 + h
            elif i == 7:  # left
                c = s - w, s + h0 - h, s, s + h0
            elif i == 8:  # top left
                c = s - w, s + h0 - hp - h, s, s + h0 - hp

            padx, pady = c[:2]
            x1, y1, x2, y2 = (max(x, 0) for x in c)  # allocate coords

            # å’Œä¸Šé¢load_mosaicå‡½æ•°çš„æ“ä½œç±»ä¼¼ æ‰¾åˆ°mosaic9å¢å¼ºåçš„labels9å’Œsegments9
            labels, segments = self.labels[index].copy(), self.segments[index].copy()
            if labels.size:
                labels[:, 1:] = xywhn2xyxy(labels[:, 1:], w, h, padx, pady)  # normalized xywh to pixel xyxy format
                segments = [xyn2xy(x, w, h, padx, pady) for x in segments]
            labels9.append(labels)
            segments9.extend(segments)

            # ç”Ÿæˆå¯¹åº”çš„img9å›¾ç‰‡(å°†å¯¹åº”ä½ç½®çš„å›¾ç‰‡åµŒå…¥img9ä¸­)
            img9[y1:y2, x1:x2] = img[y1 - pady:, x1 - padx:]  # img9[ymin:ymax, xmin:xmax]
            hp, wp = h, w  # height, width previous

        # Offset
        yc, xc = (int(random.uniform(0, s)) for _ in self.mosaic_border)  # mosaic center x, y
        img9 = img9[yc:yc + 2 * s, xc:xc + 2 * s]

        # Concat/clip labels
        labels9 = np.concatenate(labels9, 0)
        labels9[:, [1, 3]] -= xc
        labels9[:, [2, 4]] -= yc
        c = np.array([xc, yc])  # centers
        segments9 = [x - c for x in segments9]

        for x in (labels9[:, 1:], *segments9):
            np.clip(x, 0, 2 * s, out=x)  # clip when using random_perspective()
        # img9, labels9 = replicate(img9, labels9)  # replicate

        # Augment åŒæ ·è¿›è¡Œ éšæœºé€è§†å˜æ¢
        img9, labels9 = random_perspective(img9, labels9, segments9,
                                           degrees=self.hyp['degrees'],
                                           translate=self.hyp['translate'],
                                           scale=self.hyp['scale'],
                                           shear=self.hyp['shear'],
                                           perspective=self.hyp['perspective'],
                                           border=self.mosaic_border)  # border to remove

        return img9, labels9

    @staticmethod
    def collate_fn(batch):
        # æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°ä¸€èˆ¬æ˜¯å½“è°ƒç”¨äº†batch_sizeæ¬¡getitemå‡½æ•°åæ‰ä¼šè°ƒç”¨ä¸€æ¬¡è¿™ä¸ªå‡½æ•°ï¼Œå¯¹batch_sizeå¼ å›¾ç‰‡å’Œå¯¹åº”çš„labelè¿›è¡Œæ‰“åŒ…ã€‚
        # å¼ºçƒˆå»ºè®®è¿™é‡Œå¤§å®¶debugè¯•è¯•è¿™é‡Œreturnçš„æ•°æ®æ˜¯ä¸æ˜¯æˆ‘è¯´çš„è¿™æ ·å®šä¹‰çš„ã€‚
        """
            å¾ˆå¤šäººä»¥ä¸ºå†™å®Œ init å’Œ getitem å‡½æ•°æ•°æ®å¢å¼ºå°±åšå®Œäº†ï¼Œ
            æˆ‘ä»¬åœ¨åˆ†ç±»ä»»åŠ¡ä¸­çš„ç¡®å†™å®Œè¿™ä¸¤ä¸ªå‡½æ•°å°±å¯ä»¥äº†ï¼Œå› ä¸ºç³»ç»Ÿä¸­æ˜¯ç»™æˆ‘ä»¬å†™å¥½äº†ä¸€ä¸ªcollate_fnå‡½æ•°çš„ï¼Œ

            ä½†æ˜¯åœ¨ç›®æ ‡æ£€æµ‹ä¸­æˆ‘ä»¬å´éœ€è¦é‡å†™collate_fnå‡½æ•°ï¼Œä¸‹é¢æˆ‘ä¼šä»”ç»†çš„è®²è§£è¿™æ ·åšçš„åŸå› ï¼ˆä»£ç ä¸­æ³¨é‡Šï¼‰ã€‚

            è¿™ä¸ªå‡½æ•°ä¼šåœ¨create_dataloaderä¸­ç”Ÿæˆdataloaderæ—¶è°ƒç”¨ï¼š
        """

        """è¿™ä¸ªå‡½æ•°ä¼šåœ¨create_dataloaderä¸­ç”Ÿæˆdataloaderæ—¶è°ƒç”¨ï¼š
               æ•´ç†å‡½æ•°  å°†imageå’Œlabelæ•´åˆåˆ°ä¸€èµ·
               :return torch.stack(img, 0): å¦‚[16, 3, 640, 640] æ•´ä¸ªbatchçš„å›¾ç‰‡
               :return torch.cat(label, 0): å¦‚[15, 6] [num_target, img_index+class_index+xywh(normalized)] æ•´ä¸ªbatchçš„label
               :return path: æ•´ä¸ªbatchæ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„
               :return shapes: (h0, w0), ((h / h0, w / w0), pad)    for COCO mAP rescaling
               pytorchçš„DataLoaderæ‰“åŒ…ä¸€ä¸ªbatchçš„æ•°æ®é›†æ—¶è¦ç»è¿‡æ­¤å‡½æ•°è¿›è¡Œæ‰“åŒ… é€šè¿‡é‡å†™æ­¤å‡½æ•°å®ç°æ ‡ç­¾ä¸å›¾ç‰‡å¯¹åº”çš„åˆ’åˆ†ï¼Œä¸€ä¸ªbatchä¸­å“ªäº›æ ‡ç­¾å±äºå“ªä¸€å¼ å›¾ç‰‡,å½¢å¦‚
                   [[0, 6, 0.5, 0.5, 0.26, 0.35],
                    [0, 6, 0.5, 0.5, 0.26, 0.35],
                    [1, 6, 0.5, 0.5, 0.26, 0.35],
                    [2, 6, 0.5, 0.5, 0.26, 0.35],]
                  å‰ä¸¤è¡Œæ ‡ç­¾å±äºç¬¬ä¸€å¼ å›¾ç‰‡, ç¬¬ä¸‰è¡Œå±äºç¬¬äºŒå¼ ã€‚ã€‚ã€‚
       """

        # img: ä¸€ä¸ªtuple ç”±batch_sizeä¸ªtensorç»„æˆ æ•´ä¸ªbatchä¸­æ¯ä¸ªtensorè¡¨ç¤ºä¸€å¼ å›¾ç‰‡
        # label: ä¸€ä¸ªtuple ç”±batch_sizeä¸ªtensorç»„æˆ æ¯ä¸ªtensorå­˜æ”¾ä¸€å¼ å›¾ç‰‡çš„æ‰€æœ‰çš„targetä¿¡æ¯
        #        label[6, object_num] 6ä¸­çš„ç¬¬ä¸€ä¸ªæ•°ä»£è¡¨ä¸€ä¸ªbatchä¸­çš„ç¬¬å‡ å¼ å›¾
        # path: ä¸€ä¸ªtuple ç”±4ä¸ªstrç»„æˆ, æ¯ä¸ªstrå¯¹åº”ä¸€å¼ å›¾ç‰‡çš„åœ°å€ä¿¡æ¯

        img, label, path, shapes = zip(*batch)  # transposed
        for i, lb in enumerate(label):
            lb[:, 0] = i  # add target image index for build_targets()

        # è¿”å›çš„
        #      img=[batch_size, 3, 736, 736]
        #      torch.stack(img, 0): å°†batch_sizeä¸ª[3, 736, 736]çš„çŸ©é˜µæ‹¼æˆä¸€ä¸ª[batch_size, 3, 736, 736]
        #      label=[target_sums, 6]  6ï¼šè¡¨ç¤ºå½“å‰targetå±äºå“ªä¸€å¼ å›¾+class+x+y+w+h
        #      torch.cat(label, 0): å°†[n1,6]ã€[n2,6]ã€[n3,6]...æ‹¼æ¥æˆ[n1+n2+n3+..., 6]
        # è¿™é‡Œä¹‹æ‰€ä»¥æ‹¼æ¥çš„æ–¹å¼ä¸åŒæ˜¯å› ä¸ºimgæ‹¼æ¥çš„æ—¶å€™å®ƒçš„æ¯ä¸ªéƒ¨åˆ†çš„å½¢çŠ¶æ˜¯ç›¸åŒçš„ï¼Œéƒ½æ˜¯[3, 736, 736]
        # ä½†labelçš„æ¯ä¸ªéƒ¨åˆ†çš„å½¢çŠ¶æ˜¯ä¸ä¸€å®šç›¸åŒçš„ï¼Œæ¯å¼ å›¾çš„ç›®æ ‡ä¸ªæ•°æ˜¯ä¸ä¸€å®šç›¸åŒçš„ï¼ˆlabelè‚¯å®šä¹Ÿå¸Œæœ›ç”¨stack,æ›´æ–¹ä¾¿,ä½†æ˜¯ä¸èƒ½é‚£æ ·æ‹¼ï¼‰
        # å¦‚æœæ¯å¼ å›¾çš„ç›®æ ‡ä¸ªæ•°æ˜¯ç›¸åŒçš„ï¼Œé‚£æˆ‘ä»¬å°±å¯èƒ½ä¸éœ€è¦é‡å†™collate_fnå‡½æ•°äº†
        return torch.stack(img, 0), torch.cat(label, 0), path, shapes

    @staticmethod
    def collate_fn4(batch):
        """
                åŒæ ·åœ¨create_dataloaderä¸­ç”Ÿæˆdataloaderæ—¶è°ƒç”¨ï¼š
                è¿™é‡Œæ˜¯yolo-v5ä½œè€…å®éªŒæ€§çš„ä¸€ä¸ªä»£ç  quad-collate function
                        å½“train.pyçš„optå‚æ•°quad=True åˆ™è°ƒç”¨collate_fn4ä»£æ›¿collate_fn
                ä½œç”¨:  å¦‚ä¹‹å‰ç”¨collate_fnå¯ä»¥è¿”å›å›¾ç‰‡[16, 3, 640, 640]ï¼Œä½†æ˜¯ç»è¿‡collate_fn4åˆ™è¿”å›å›¾ç‰‡[4, 3, 1280, 1280]
                      å°†4å¼ mosaicå›¾ç‰‡[1, 3, 640, 640]åˆæˆä¸€å¼ å¤§çš„mosaicå›¾ç‰‡[1, 3, 1280, 1280]
                      å°†ä¸€ä¸ªbatchçš„å›¾ç‰‡æ¯å››å¼ å¤„ç†, 0.5çš„æ¦‚ç‡å°†å››å¼ å›¾ç‰‡æ‹¼æ¥åˆ°ä¸€å¼ å¤§å›¾ä¸Šè®­ç»ƒ, 0.5æ¦‚ç‡ç›´æ¥å°†æŸå¼ å›¾ç‰‡ä¸Šé‡‡æ ·ä¸¤å€è®­ç»ƒ
                """

        # img: æ•´ä¸ªbatchçš„å›¾ç‰‡ [16, 3, 640, 640]
        # label: æ•´ä¸ªbatchçš„labelæ ‡ç­¾ [num_target, img_index+class_index+xywh(normalized)]
        # path: æ•´ä¸ªbatchæ‰€æœ‰å›¾ç‰‡çš„è·¯å¾„
        # shapes: (h0, w0), ((h / h0, w / w0), pad)    for COCO mAP rescaling
        img, label, path, shapes = zip(*batch)  # transposed
        n = len(shapes) // 4 # collate_fn4å¤„ç†åè¿™ä¸ªbatchä¸­å›¾ç‰‡çš„ä¸ªæ•°
        img4, label4, path4, shapes4 = [], [], path[:n], shapes[:n] # åˆå§‹åŒ–

        ho = torch.tensor([[0.0, 0, 0, 1, 0, 0]])
        wo = torch.tensor([[0.0, 0, 1, 0, 0, 0]])
        s = torch.tensor([[1, 1, 0.5, 0.5, 0.5, 0.5]])  # scale
        for i in range(n):  # zidane torch.zeros(16,3,720,1280)  # BCHW
            i *= 4  # é‡‡æ · [0, 4, 8, 16]
            if random.random() < 0.5:
                # éšæœºæ•°å°äº0.5å°±ç›´æ¥å°†æŸå¼ å›¾ç‰‡ä¸Šé‡‡æ ·ä¸¤å€è®­ç»ƒ
                im = F.interpolate(img[i].unsqueeze(0).float(), scale_factor=2.0, mode='bilinear', align_corners=False)[
                    0].type(img[i].type())
                lb = label[i]
            else:
                # éšæœºæ•°å¤§äº0.5å°±å°†å››å¼ å›¾ç‰‡(mosaicåçš„)æ‹¼æ¥åˆ°ä¸€å¼ å¤§å›¾ä¸Šè®­ç»ƒ
                im = torch.cat((torch.cat((img[i], img[i + 1]), 1), torch.cat((img[i + 2], img[i + 3]), 1)), 2)
                lb = torch.cat((label[i], label[i + 1] + ho, label[i + 2] + wo, label[i + 3] + ho + wo), 0) * s
            img4.append(im)
            label4.append(lb)

        # åé¢è¿”å›çš„éƒ¨åˆ†å’Œcollate_fnå°±å·®ä¸å¤šäº† åŸå› å’Œè§£é‡Šéƒ½å†™åœ¨ä¸Šä¸€ä¸ªå‡½æ•°äº† è‡ªå·±debugçœ‹ä¸€ä¸‹å§
        for i, lb in enumerate(label4):
            lb[:, 0] = i  # add target image index for build_targets()

        return torch.stack(img4, 0), torch.cat(label4, 0), path4, shapes4


# Ancillary functions --------------------------------------------------------------------------------------------------

# ä¸¤ä¸ªæ–‡ä»¶æ“ä½œ
def create_folder(path='./new'):
    """
        create_folderå‡½æ•°ç”¨äºåˆ›å»ºä¸€ä¸ªæ–°çš„æ–‡ä»¶å¤¹ã€‚ä¼šç”¨åœ¨ä¸‹é¢çš„flatten_recursiveå‡½æ•°ä¸­ã€‚
        ç”¨åœ¨flatten_recursiveå‡½æ•°ä¸­
        åˆ›å»ºæ–‡ä»¶å¤¹  Create folder
        """
    # å¦‚æœpathå­˜åœ¨æ–‡ä»¶å¤¹ï¼Œåˆ™ç§»é™¤
    if os.path.exists(path):
        shutil.rmtree(path)  # delete output folder
    # å†ä»æ–°æ–°å»ºè¿™ä¸ªæ–‡ä»¶å¤¹
    os.makedirs(path)  # make new output folder


def flatten_recursive(path=DATASETS_DIR / 'coco128'):
    """
        è¿™ä¸ªæ¨¡å—æ˜¯å°†ä¸€ä¸ªæ–‡ä»¶è·¯å¾„ä¸­çš„æ‰€æœ‰æ–‡ä»¶å¤åˆ¶åˆ°å¦ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­ å³å°†imageæ–‡ä»¶å’Œlabelæ–‡ä»¶æ”¾åˆ°ä¸€ä¸ªæ–°æ–‡ä»¶å¤¹ä¸­ã€‚
    """
    # Flatten a recursive directory by bringing all files to top level
    new_path = Path(str(path) + '_flat')
    create_folder(new_path)
    for file in tqdm(glob.glob(str(Path(path)) + '/**/*.*', recursive=True)):
        # shutil.copyfile: å¤åˆ¶æ–‡ä»¶åˆ°å¦ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­
        shutil.copyfile(file, new_path / Path(file).name)


def extract_boxes(path=DATASETS_DIR / 'coco128'):  # from utils.datasets import *; extract_boxes()

    """
        è‡ªè¡Œä½¿ç”¨ ç”Ÿæˆåˆ†ç±»æ•°æ®é›†
        è¿™ä¸ªæ¨¡å—æ˜¯å°†ç›®æ ‡æ£€æµ‹æ•°æ®é›†è½¬åŒ–ä¸ºåˆ†ç±»æ•°æ®é›†
        é›†ä½“åšæ³•: æŠŠç›®æ ‡æ£€æµ‹æ•°æ®é›†ä¸­çš„æ¯ä¸€ä¸ªgtæ‹†è§£å¼€ åˆ†ç±»åˆ«å­˜å‚¨åˆ°å¯¹åº”çš„æ–‡ä»¶å½“ä¸­ã€‚
    """

    """
        Convert detection dataset into classification dataset, with one directory per class
        ä½¿ç”¨: from utils.datasets import *; extract_boxes()
        :params path: æ•°æ®é›†åœ°å€
    """
    path = Path(path)  # images dir æ•°æ®é›†æ–‡ä»¶ç›®å½• é»˜è®¤'..\datasets\coco128'
    # remove existing path / 'classifier' æ–‡ä»¶å¤¹
    shutil.rmtree(path / 'classifier') if (path / 'classifier').is_dir() else None  # remove existing
    files = list(path.rglob('*.*')) # é€’å½’éå†pathæ–‡ä»¶ä¸‹çš„'*.*'æ–‡ä»¶
    n = len(files)  # number of files
    for im_file in tqdm(files, total=n):
        if im_file.suffix[1:] in IMG_FORMATS: # å¿…é¡»å¾—æ˜¯å›¾ç‰‡æ–‡ä»¶
            # image
            im = cv2.imread(str(im_file))[..., ::-1]  # BGR to RGB
            h, w = im.shape[:2] # å¾—åˆ°è¿™å¼ å›¾ç‰‡h w

            # labels æ ¹æ®è¿™å¼ å›¾ç‰‡çš„è·¯å¾„æ‰¾åˆ°è¿™å¼ å›¾ç‰‡çš„labelè·¯å¾„
            lb_file = Path(img2label_paths([str(im_file)])[0])
            if Path(lb_file).exists():
                with open(lb_file) as f:
                    lb = np.array([x.split() for x in f.read().strip().splitlines()], dtype=np.float32)  # labels

                for j, x in enumerate(lb):  # éå†æ¯ä¸€ä¸ªgt
                    c = int(x[0])  # class
                    # ç”Ÿæˆæ–°'file_name path\classifier\class_index\image_name'
                    # å¦‚: 'F:\yolo_v5\datasets\coco128\images\train2017\classifier\45\train2017_000000000009_0.jpg'
                    f = (path / 'classifier') / f'{c}' / f'{path.stem}_{im_file.stem}_{j}.jpg'  # new filename
                    # f.parent: 'F:\yolo_v5\datasets\coco128\images\train2017\classifier\45'
                    if not f.parent.is_dir():
                        # æ¯ä¸€ä¸ªç±»åˆ«çš„ç¬¬ä¸€å¼ ç…§ç‰‡å­˜è¿›å»ä¹‹å‰ å…ˆåˆ›å»ºå¯¹åº”ç±»çš„æ–‡ä»¶å¤¹
                        f.parent.mkdir(parents=True)

                    b = x[1:] * [w, h, w, h]   # box   normalized to æ­£å¸¸å¤§å°
                    # b[2:] = b[2:].max()  # rectangle to square
                    b[2:] = b[2:] * 1.2 + 3  # pad
                    b = xywh2xyxy(b.reshape(-1, 4)).ravel().astype(np.int)

                    # é˜²æ­¢bå‡ºç•Œ clip boxes outside of image
                    b[[0, 2]] = np.clip(b[[0, 2]], 0, w)  # clip boxes outside of image
                    b[[1, 3]] = np.clip(b[[1, 3]], 0, h)
                    assert cv2.imwrite(str(f), im[b[1]:b[3], b[0]:b[2]]), f'box failure in {f}'


def autosplit(path=DATASETS_DIR / 'coco128/images', weights=(0.9, 0.1, 0.0), annotated_only=False):
    """
        è¿™ä¸ªæ¨¡å—æ˜¯è¿›è¡Œè‡ªåŠ¨åˆ’åˆ†æ•°æ®é›†ã€‚å½“ä½¿ç”¨è‡ªå·±æ•°æ®é›†æ—¶ï¼Œå¯ä»¥ç”¨è¿™ä¸ªæ¨¡å—è¿›è¡Œè‡ªè¡Œåˆ’åˆ†æ•°æ®é›†ã€‚
    """

    """
        è‡ªåŠ¨å°†æ•°æ®é›†åˆ’åˆ†ä¸ºtrain/val/testå¹¶ä¿å­˜ path/autosplit_*.txt files
        Usage: from utils.datasets import *; autosplit()
        :params path: æ•°æ®é›†imageä½ç½®
        :params weights: åˆ’åˆ†æƒé‡ é»˜è®¤åˆ†åˆ«æ˜¯(0.9, 0.1, 0.0) å¯¹åº”(train, val, test)
        :params annotated_only: Only use images with an annotated txt file
    """
    path = Path(path)  # images dir
    # è·å–imagesä¸­æ‰€æœ‰çš„å›¾ç‰‡ image files only
    files = sorted(x for x in path.rglob('*.*') if x.suffix[1:].lower() in IMG_FORMATS)  # image files only
    n = len(files)  # number of files
    random.seed(0)  # éšæœºæ•°ç§å­

    # assign each image to a split æ ¹æ®(train, val, test)æƒé‡åˆ’åˆ†åŸå§‹å›¾ç‰‡æ•°æ®é›†
    # indices: [n]   0, 1, 2   åˆ†åˆ«è¡¨ç¤ºæ•°æ®é›†ä¸­æ¯ä¸€å¼ å›¾ç‰‡å±äºå“ªä¸ªæ•°æ®é›† åˆ†åˆ«å¯¹åº”ç€(train, val, test)
    indices = random.choices([0, 1, 2], weights=weights, k=n)  # assign each image to a split

    txt = ['autosplit_train.txt', 'autosplit_val.txt', 'autosplit_test.txt']  # 3 txt files
    [(path.parent / x).unlink(missing_ok=True) for x in txt]  # remove existing

    print(f'Autosplitting images from {path}' + ', using *.txt labeled images only' * annotated_only)
    for i, img in tqdm(zip(indices, files), total=n):
        if not annotated_only or Path(img2label_paths([str(img)])[0]).exists():  # check label
            with open(path.parent / txt[i], 'a') as f:
                f.write('./' + img.relative_to(path.parent).as_posix() + '\n')  # add image to txt file


def verify_image_label(args):
    """
        ç”¨åœ¨cache_labelså‡½æ•°ä¸­
        è¿™ä¸ªå‡½æ•°ç”¨äºæ£€æŸ¥æ¯ä¸€å¼ å›¾ç‰‡å’Œæ¯ä¸€å¼ labelæ–‡ä»¶æ˜¯å¦å®Œå¥½ã€‚
        å›¾ç‰‡æ–‡ä»¶: æ£€æŸ¥å†…å®¹ã€æ ¼å¼ã€å¤§å°ã€å®Œæ•´æ€§
        labelæ–‡ä»¶: æ£€æŸ¥æ¯ä¸ªgtå¿…é¡»æ˜¯çŸ©å½¢(æ¯è¡Œéƒ½å¾—æ˜¯5ä¸ªæ•°class+xywh) + æ ‡ç­¾æ˜¯å¦å…¨éƒ¨>=0 + æ ‡ç­¾åæ ‡xywhæ˜¯å¦å½’ä¸€åŒ– + æ ‡ç­¾ä¸­æ˜¯å¦æœ‰é‡å¤çš„åæ ‡
    """

    """
        :params im_file: æ•°æ®é›†ä¸­ä¸€å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
        :params lb_file: æ•°æ®é›†ä¸­ä¸€å¼ å›¾ç‰‡çš„labelç›¸å¯¹è·¯å¾„
        :params prefix: æ—¥å¿—å¤´éƒ¨ä¿¡æ¯(å½©æ‰“é«˜äº®éƒ¨åˆ†)
        
        :return im_file: å½“å‰è¿™å¼ å›¾ç‰‡çš„pathç›¸å¯¹è·¯å¾„
        :return l: [gt_num, cls+xywh(normalized)]
                   å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ lå°±å­˜å‚¨åŸlabel(å…¨éƒ¨æ˜¯æ­£å¸¸çŸ©å½¢æ ‡ç­¾)
                   å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾  lå°±å­˜å‚¨ç»è¿‡segments2boxeså¤„ç†å¥½çš„æ ‡ç­¾(æ­£å¸¸çŸ©å½¢æ ‡ç­¾ä¸å¤„ç† å¤šè¾¹å½¢æ ‡ç­¾è½¬åŒ–ä¸ºçŸ©å½¢æ ‡ç­¾)
        :return shape: å½“å‰è¿™å¼ å›¾ç‰‡çš„å½¢çŠ¶ shape
        :return segments: å¦‚æœè¿™å¼ å›¾ç‰‡æ²¡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å­˜å‚¨None
                          å¦‚æœè¿™å¼ å›¾ç‰‡æœ‰ä¸€ä¸ªsegmentå¤šè¾¹å½¢æ ‡ç­¾ å°±æŠŠè¿™å¼ å›¾ç‰‡çš„æ‰€æœ‰labelå­˜å‚¨åˆ°segmentsä¸­(è‹¥å¹²ä¸ªæ­£å¸¸gt è‹¥å¹²ä¸ªå¤šè¾¹å½¢æ ‡ç­¾) [gt_num, xy1...]
        :return nm: number missing å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦ä¸¢å¤±         ä¸¢å¤±=1    å­˜åœ¨=0
        :return nf: number found å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦å­˜åœ¨           å­˜åœ¨=1    ä¸¢å¤±=0
        :return ne: number empty å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ˜¯å¦æ˜¯ç©ºçš„         ç©ºçš„=1    æ²¡ç©º=0
        :return nc: number corrupt å½“å‰è¿™å¼ å›¾ç‰‡çš„labelæ–‡ä»¶æ˜¯å¦æ˜¯ç ´æŸçš„  ç ´æŸçš„=1  æ²¡ç ´æŸ=0
        :return msg: è¿”å›çš„msgä¿¡æ¯  labelæ–‡ä»¶å®Œå¥½=â€˜â€™  labelæ–‡ä»¶ç ´æŸ=warningä¿¡æ¯
        """
    im_file, lb_file, prefix = args
    segments = []  # å­˜æ”¾è¿™å¼ å›¾æ‰€æœ‰gtæ¡†çš„ä¿¡æ¯(åŒ…å«segmentså¤šè¾¹å½¢: labelæŸä¸€åˆ—æ•°å¤§äº8)
    nm, nf, ne, nc, msg = 0, 0, 0, 0, '',  # number (missing, found, empty, corrupt), message, segments

    try:
        # æ£€æŸ¥è¿™å¼ å›¾ç‰‡(å†…å®¹ã€æ ¼å¼ã€å¤§å°ã€å®Œæ•´æ€§) verify images
        im = Image.open(im_file) # æ‰“å¼€å›¾ç‰‡æ–‡ä»¶
        im.verify()  # PIL verify æ£€æŸ¥å›¾ç‰‡å†…å®¹å’Œæ ¼å¼æ˜¯å¦æ­£å¸¸
        shape = exif_size(im)   # å½“å‰å›¾ç‰‡çš„å¤§å° image size
        assert (shape[0] > 9) & (shape[1] > 9), f'image size {shape} <10 pixels'  # å›¾ç‰‡å¤§å°å¿…é¡»å¤§äº9ä¸ªpixels
        assert im.format.lower() in IMG_FORMATS, f'invalid image format {im.format}' # å›¾ç‰‡æ ¼å¼å¿…é¡»åœ¨img_formatä¸­
        if im.format.lower() in ('jpg', 'jpeg'): # æ£€æŸ¥jpgæ ¼å¼æ–‡ä»¶
            with open(im_file, 'rb') as f:
                # f.seek: -2 åç§»é‡ å‘æ–‡ä»¶å¤´æ–¹å‘ä¸­ç§»åŠ¨çš„å­—èŠ‚æ•° 2 ç›¸å¯¹ä½ç½® ä»æ–‡ä»¶å°¾å¼€å§‹åç§»
                f.seek(-2, 2)
                # f.read(): è¯»å–å›¾ç‰‡æ–‡ä»¶  æŒ‡ä»¤:\xff\xd9æ£€æµ‹æ•´å¼ å›¾ç‰‡æ˜¯å¦å®Œæ•´,å¦‚æœä¸å®Œæ•´å°±è¿”å›corrupted JPEG
                if f.read() != b'\xff\xd9':  # corrupt JPEG
                    ImageOps.exif_transpose(Image.open(im_file)).save(im_file, 'JPEG', subsampling=0, quality=100)
                    msg = f'{prefix}WARNING: {im_file}: corrupt JPEG restored and saved'

        # verify labels
        if os.path.isfile(lb_file): # å¦‚æœè¿™ä¸ªlabelè·¯å¾„å­˜åœ¨
            nf = 1  # label found
            with open(lb_file) as f: # è¯»å–labelæ–‡ä»¶
                # è¯»å–å½“å‰labelæ–‡ä»¶çš„æ¯ä¸€è¡Œ: æ¯ä¸€è¡Œéƒ½æ˜¯å½“å‰å›¾ç‰‡çš„ä¸€ä¸ªgt
                lb = [x.split() for x in f.read().strip().splitlines() if len(x)]
                # any() å‡½æ•°ç”¨äºåˆ¤æ–­ç»™å®šçš„å¯è¿­ä»£å‚æ•° æ˜¯å¦å…¨éƒ¨ä¸ºFalse,åˆ™è¿”å› False; å¦‚æœæœ‰ä¸€ä¸ªä¸º True,åˆ™è¿”å›True
                # å¦‚æœå½“å‰å›¾ç‰‡çš„labelæ–‡ä»¶æŸä¸€åˆ—æ•°å¤§äº8, åˆ™è®¤ä¸ºlabelæ˜¯å­˜åœ¨segmentçš„polygonç‚¹(å¤šè¾¹å½¢)  å°±ä¸æ˜¯çŸ©é˜µ åˆ™å°†labelä¿¡æ¯å­˜å…¥segmentä¸­
                if any([len(x) > 8 for x in lb]):  # is segment
                    # å½“å‰å›¾ç‰‡ä¸­æ‰€æœ‰gtæ¡†çš„ç±»åˆ«
                    classes = np.array([x[0] for x in lb], dtype=np.float32)
                    # è·å¾—è¿™å¼ å›¾ä¸­æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾)
                    # å› ä¸ºsegmentæ ‡ç­¾å¯ä»¥æ˜¯ä¸åŒé•¿åº¦ï¼Œæ‰€ä»¥è¿™é‡Œsegmentsæ˜¯ä¸€ä¸ªåˆ—è¡¨ [gt_num, xy1...(normalized)]
                    segments = [np.array(x[1:], dtype=np.float32).reshape(-1, 2) for x in lb]  # (cls, xy1...)
                    # è·å¾—è¿™å¼ å›¾ä¸­æ‰€æœ‰gtæ¡†çš„labelä¿¡æ¯(ä¸åŒ…å«segmentå¤šè¾¹å½¢æ ‡ç­¾)
                    # segments(å¤šè¾¹å½¢) -> bbox(æ­£æ–¹å½¢), å¾—åˆ°æ–°æ ‡ç­¾  [gt_num, cls+xywh(normalized)]
                    lb = np.concatenate((classes.reshape(-1, 1), segments2boxes(segments)), 1)  # (cls, xywh)
                lb = np.array(lb, dtype=np.float32)
            nl = len(lb)
            if nl:
                # åˆ¤æ–­æ ‡ç­¾æ˜¯å¦æœ‰äº”åˆ—
                assert lb.shape[1] == 5, f'labels require 5 columns, {lb.shape[1]} columns detected'
                # åˆ¤æ–­æ ‡ç­¾æ˜¯å¦å…¨éƒ¨>=0
                assert (lb >= 0).all(), f'negative label values {lb[lb < 0]}'
                # åˆ¤æ–­æ ‡ç­¾åæ ‡x y w hæ˜¯å¦å½’ä¸€åŒ–
                assert (lb[:, 1:] <= 1).all(), f'non-normalized or out of bounds coordinates {lb[:, 1:][lb[:, 1:] > 1]}'
                # åˆ¤æ–­æ ‡ç­¾ä¸­æ˜¯å¦æœ‰é‡å¤çš„åæ ‡
                _, i = np.unique(lb, axis=0, return_index=True)
                if len(i) < nl:  # duplicate row check
                    lb = lb[i]  # remove duplicates
                    if segments:
                        segments = segments[i]
                    msg = f'{prefix}WARNING: {im_file}: {nl - len(i)} duplicate labels removed'
            else:
                ne = 1  # label empty  l.shape[0] == 0åˆ™ä¸ºç©ºçš„æ ‡ç­¾ï¼Œne=1
                lb = np.zeros((0, 5), dtype=np.float32)
        else:
            nm = 1  # label missing  ä¸å­˜åœ¨æ ‡ç­¾æ–‡ä»¶ï¼Œåˆ™nm = 1
            lb = np.zeros((0, 5), dtype=np.float32)
        return im_file, lb, shape, segments, nm, nf, ne, nc, msg
    except Exception as e:
        nc = 1
        msg = f'{prefix}WARNING: {im_file}: ignoring corrupt image/label: {e}'
        return [None, None, None, None, nm, nf, ne, nc, msg]


def dataset_stats(path='coco128.yaml', autodownload=False, verbose=False, profile=False, hub=False):
    """
        è¿™ä¸ªæ¨¡å—æ˜¯ç»Ÿè®¡æ•°æ®é›†çš„ä¿¡æ¯è¿”å›çŠ¶æ€å­—å…¸ã€‚åŒ…å«: æ¯ä¸ªç±»åˆ«çš„å›¾ç‰‡æ•°é‡ + æ¯ä¸ªç±»åˆ«çš„å®ä¾‹æ•°é‡ã€‚
        olov5æ•°æ®é›†æ²¡æœ‰ç”¨  è‡ªè¡Œä½¿ç”¨
    """

    """
        Return dataset statistics dictionary with images and instances counts per split per class
        Usage: from utils.datasets import *; dataset_stats('coco128.yaml', verbose=True)
        
        :params path: æ•°æ®é›†ä¿¡æ¯  data.yaml
        :params autodownload: Attempt to download dataset if not found locally
        :params verbose: printå¯è§†åŒ–æ‰“å°
        
        :return stats: ç»Ÿè®¡çš„æ•°æ®é›†ä¿¡æ¯ è¯¦ç»†ä»‹ç»çœ‹åé¢
    """

    def round_labels(labels):
        # Update labels to integer class and 6 decimal place floats
        return [[int(c), *(round(x, 4) for x in points)] for c, *points in labels]

    def unzip(path):
        # Unzip data.zip TODO: CONSTRAINT: path/to/abc.zip MUST unzip to 'path/to/abc/'
        if str(path).endswith('.zip'):  # path is data.zip
            assert Path(path).is_file(), f'Error unzipping {path}, file not found'
            ZipFile(path).extractall(path=path.parent)  # unzip
            dir = path.with_suffix('')  # dataset directory == zip name
            return True, str(dir), next(dir.rglob('*.yaml'))  # zipped, data_dir, yaml_path
        else:  # path is data.yaml
            return False, None, path

    def hub_ops(f, max_dim=1920):
        # HUB ops for 1 image 'f': resize and save at reduced quality in /dataset-hub for web/app viewing
        f_new = im_dir / Path(f).name  # dataset-hub image filename
        try:  # use PIL
            im = Image.open(f)
            r = max_dim / max(im.height, im.width)  # ratio
            if r < 1.0:  # image too large
                im = im.resize((int(im.width * r), int(im.height * r)))
            im.save(f_new, 'JPEG', quality=75, optimize=True)  # save
        except Exception as e:  # use OpenCV
            print(f'WARNING: HUB ops PIL failure {f}: {e}')
            im = cv2.imread(f)
            im_height, im_width = im.shape[:2]
            r = max_dim / max(im_height, im_width)  # ratio
            if r < 1.0:  # image too large
                im = cv2.resize(im, (int(im_width * r), int(im_height * r)), interpolation=cv2.INTER_AREA)
            cv2.imwrite(str(f_new), im)

    zipped, data_dir, yaml_path = unzip(Path(path))
    with open(check_yaml(yaml_path), errors='ignore') as f:
        data = yaml.safe_load(f)  # data dict
        if zipped:
            data['path'] = data_dir  # TODO: should this be dir.resolve()?
    check_dataset(data, autodownload)  # download dataset if missing
    hub_dir = Path(data['path'] + ('-hub' if hub else ''))
    stats = {'nc': data['nc'], 'names': data['names']}  # statistics dictionary
    for split in 'train', 'val', 'test': # åˆ†trainã€valã€testç»Ÿè®¡æ•°æ®é›†ä¿¡æ¯
        if data.get(split) is None:
            stats[split] = None  # i.e. no test set
            continue
        x = []
        dataset = LoadImagesAndLabels(data[split])  # load dataset

        # ç»Ÿè®¡æ•°æ®é›†æ¯ä¸ªå›¾ç‰‡labelä¸­æ¯ä¸ªç±»åˆ«gtæ¡†çš„ä¸ªæ•°
        # x: {list: img_num} æ¯ä¸ªlist[class_num]  æ¯ä¸ªå›¾ç‰‡çš„labelä¸­æ¯ä¸ªç±»åˆ«gtæ¡†çš„ä¸ªæ•°
        for label in tqdm(dataset.labels, total=dataset.n, desc='Statistics'):
            x.append(np.bincount(label[:, 0].astype(int), minlength=data['nc']))
        x = np.array(x)  #   # list to numpyçŸ©é˜µ  [img_num, class_num] shape(128x80)
        # åˆ†åˆ«ç»Ÿè®¡trainã€valã€testä¸‰ä¸ªæ•°æ®é›†çš„æ•°æ®ä¿¡æ¯
        # åŒ…æ‹¬: 'image_stats': å­—å…¸dict  å›¾ç‰‡æ•°é‡total  æ²¡æœ‰æ ‡ç­¾çš„æ–‡ä»¶ä¸ªæ•°unlabelled  æ•°æ®é›†æ¯ä¸ªç±»åˆ«çš„gtä¸ªæ•°[80]
        # 'instance_stats': å­—å…¸dict  æ•°æ®é›†ä¸­æ‰€æœ‰å›¾ç‰‡çš„æ‰€æœ‰gtä¸ªæ•°total   æ•°æ®é›†ä¸­æ¯ä¸ªç±»åˆ«çš„gtä¸ªæ•°[80]
        # 'labels': å­—å…¸dict  key=æ•°æ®é›†ä¸­æ¯å¼ å›¾ç‰‡çš„æ–‡ä»¶å  value=æ¯å¼ å›¾ç‰‡å¯¹åº”çš„labelä¿¡æ¯ [n, cls+xywh]
        stats[split] = {'instance_stats': {'total': int(x.sum()), 'per_class': x.sum(0).tolist()},
                        'image_stats': {'total': dataset.n, 'unlabelled': int(np.all(x == 0, 1).sum()),
                                        'per_class': (x > 0).sum(0).tolist()},
                        'labels': [{str(Path(k).name): round_labels(v.tolist())} for k, v in
                                   zip(dataset.img_files, dataset.labels)]}

        if hub:
            im_dir = hub_dir / 'images'
            im_dir.mkdir(parents=True, exist_ok=True)
            for _ in tqdm(ThreadPool(NUM_THREADS).imap(hub_ops, dataset.img_files), total=dataset.n, desc='HUB Ops'):
                pass

    # Profile
    stats_path = hub_dir / 'stats.json'
    if profile:
        for _ in range(1):
            file = stats_path.with_suffix('.npy')
            t1 = time.time()
            np.save(file, stats)
            t2 = time.time()
            x = np.load(file, allow_pickle=True)
            print(f'stats.npy times: {time.time() - t2:.3f}s read, {t2 - t1:.3f}s write')

            file = stats_path.with_suffix('.json')
            t1 = time.time()
            with open(file, 'w') as f:
                json.dump(stats, f)  # save stats *.json
            t2 = time.time()
            with open(file) as f:
                x = json.load(f)  # load hyps dict
            print(f'stats.json times: {time.time() - t2:.3f}s read, {t2 - t1:.3f}s write')

    # Save, print and return
    if hub:
        print(f'Saving {stats_path.resolve()}...')
        with open(stats_path, 'w') as f:
            json.dump(stats, f)  # save stats.json
    if verbose:
        # printå¯è§†åŒ–
        print(json.dumps(stats, indent=2, sort_keys=False))
    return stats
